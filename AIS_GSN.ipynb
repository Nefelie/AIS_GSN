{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "from sklearn.neighbors import BallTree\n",
    "from sklearn.cluster import DBSCAN\n",
    "from collections import Counter\n",
    "from itertools import groupby\n",
    "from itertools import chain\n",
    "import pytz\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import MultiPoint\n",
    "from geopy.distance import great_circle\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from kneed import KneeLocator\n",
    "import math\n",
    "from rdp_modified import rdp_mod\n",
    "import time\n",
    "import networkx as nx\n",
    "import datetime\n",
    "import matplotlib.colors as mcolors\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# folder_loc = r\"C:\\Users\\nh2u20\\OneDrive - University of Southampton\\Uni\\3rd Year\\Individual Project\"\n",
    "folder_loc = r\"C:\\Users\\Nefelie\\OneDrive - University of Southampton\\Uni\\3rd Year\\Individual Project\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% DATA PRE-PROCESSING DATA\n",
    "\n",
    "cols = ['IMO', 'MMSI', 'latitude', 'longitude', 'sog', 'datetime']\n",
    "df_2019 = pd.read_csv(folder_loc + r\"\\bulk_carrier_data\\AIS_full_year_dates_parsed.csv\", usecols=cols)\n",
    "df_2019 = df_2019.rename(columns={'datetime': 'last_seen', 'sog': 'speed'})\n",
    "\n",
    "cols = ['IMO', 'last_seen', 'latitude', 'longitude', 'speed']\n",
    "df_2022 = pd.read_csv(folder_loc + r\"\\seanet\\seanetships.csv\", usecols=cols)\n",
    "df_2023 = pd.read_csv(folder_loc + r\"\\seanet\\olden_new_2023.csv\", usecols=cols)\n",
    "\n",
    "def clean_dataframes(dfs):\n",
    "    dfs_out = []\n",
    "    for df in dfs:\n",
    "        df = df.rename(columns={'latitude': 'lat', 'longitude': 'lon', 'last_seen': 'datetime', 'speed': 'sog'})\n",
    "        df['datetime'] =  pd.to_datetime(df['datetime'], dayfirst=True)\n",
    "        df = df.drop_duplicates(subset=['IMO', 'datetime'])\n",
    "        df = df.sort_values(by=['IMO', 'datetime'], ascending=[True, True])\n",
    "        df = df[['IMO', 'lat', 'lon', 'sog', 'datetime']] # reorder cols\n",
    "        df['sog'] = df['sog'].fillna(0)    \n",
    "        df['IMO'] = df['IMO'].astype(str)\n",
    "        dfs_out.append(df)\n",
    "    return dfs_out\n",
    "\n",
    "dfs = clean_dataframes([df_2019, df_2022, df_2023])\n",
    "\n",
    "df = pd.concat(dfs, axis=0)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting Unprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# plt.figure(figsize=(8,8), dpi=400)\n",
    "# ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "# # ax.add_feature(cfeature.LAND, facecolor=\"lightgrey\")\n",
    "# gl = ax.gridlines(draw_labels=True, alpha=0.2, color=\"k\", linestyle='--', linewidth=0.3, xlocs=range(-180, 180, 45), ylocs=range(-90, 90, 45))\n",
    "# # ax.coastlines()\n",
    "# ax.scatter(df.lon, df.lat, c='k', edgecolor='None', marker = \"x\", alpha=0.7, s=0.2, linewidth=0.02)\n",
    "# gl.top_labels = False\n",
    "# gl.right_labels = False\n",
    "# gl.xlabel_style = {'size': 8, 'color': 'k'}\n",
    "# gl.ylabel_style = {'size': 8, 'color': 'k'}\n",
    "# gl.xpadding = 15 \n",
    "# gl.ypadding = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a =  pd.read_csv(folder_loc + r\"\\bulk_carrier_data\\AIS_full_year_dates_parsed.csv\")\n",
    "# b = pd.read_csv(folder_loc + r\"\\seanet\\seanetships.csv\")\n",
    "# c = pd.read_csv(folder_loc + r\"\\seanet\\olden_new_2023.csv\")\n",
    "\n",
    "# nan_count = b[\"draft\"].isna().sum()\n",
    "# nan_percentage = nan_count / len(b) * 100\n",
    "# print(f\"{nan_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting Unprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# plt.figure(figsize=(8,8), dpi=400)\n",
    "# ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "# # ax.add_feature(cfeature.LAND, facecolor=\"lightgrey\")\n",
    "# gl = ax.gridlines(draw_labels=True, alpha=0.2, color=\"k\", linestyle='--', linewidth=0.3, xlocs=range(-180, 180, 45), ylocs=range(-90, 90, 45))\n",
    "# # ax.coastlines()\n",
    "# ax.scatter(df.lon, df.lat, c='k', edgecolor='None', marker = \"x\", alpha=0.7, s=0.2, linewidth=0.02)\n",
    "# gl.top_labels = False\n",
    "# gl.right_labels = False\n",
    "# gl.xlabel_style = {'size': 8, 'color': 'k'}\n",
    "# gl.ylabel_style = {'size': 8, 'color': 'k'}\n",
    "# gl.xpadding = 15 \n",
    "# gl.ypadding = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a =  pd.read_csv(folder_loc + r\"\\bulk_carrier_data\\AIS_full_year_dates_parsed.csv\")\n",
    "# b = pd.read_csv(folder_loc + r\"\\seanet\\seanetships.csv\")\n",
    "# c = pd.read_csv(folder_loc + r\"\\seanet\\olden_new_2023.csv\")\n",
    "\n",
    "# nan_count = b[\"draft\"].isna().sum()\n",
    "# nan_percentage = nan_count / len(b) * 100\n",
    "# print(f\"{nan_percentage:.2f}%\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter out Erroneous Speeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('df1.pkl')\n",
    "df.loc[df['sog'] == 102.3, 'sog'] = np.nan # replace anomalous sog values with nan\n",
    "df['sog'] = df['sog'].interpolate(method='pad')\n",
    "df = df[df['sog'] < 20]\n",
    "# df1.sog.plot.kde()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Other Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_np(lon1, lat1, lon2, lat2, in_deg=True):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points\n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    if in_deg:\n",
    "        lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    km = 6371.0088 * c\n",
    "    return km\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wrapping(df, geo_map=True):\n",
    "    \"\"\"\n",
    "    prevent line from plotting across map when position goes from +180 to -180\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert longitudes greater than 180 to negative values\n",
    "    df.loc[df['lon'] > 180, 'lon'] -= 360\n",
    "    \n",
    "    # Convert longitudes less than -180 to positive values\n",
    "    df.loc[df['lon'] < -180, 'lon'] += 360\n",
    "    \n",
    "    x, y = df['lon'], df['lat']\n",
    "    \n",
    "    # split the track into segments that dont cross the dateline\n",
    "    xdiff = np.diff(x)\n",
    "    wrapidx = np.where(np.abs(xdiff) > 180)[0] + 1\n",
    "    segments = np.split(df, wrapidx)   \n",
    "    \n",
    "    plt.figure(dpi=300)\n",
    "    \n",
    "    if geo_map:\n",
    "        ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "        ax.coastlines(linewidth=0.35)\n",
    "        # ax.add_feature(cfeature.LAND)\n",
    "        # ax.add_feature(cfeature.OCEAN)\n",
    "        # ax.add_feature(cfeature.BORDERS, linestyle='-', alpha=.5)\n",
    "    \n",
    "    \n",
    "    # Plot each segment separately\n",
    "    for i, seg in enumerate(segments):\n",
    "        x, y = seg['lon'], seg['lat']\n",
    "        plt.plot(x, y, linewidth=0.1, c=\"k\", transform=ccrs.Geodetic())\n",
    "        plt.xlabel(\"longitude\")\n",
    "        plt.ylabel(\"latitude\")\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Erroneous Positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% DROP ERRONEOUS POSITIONS\n",
    "\n",
    "def calc_distances(df):\n",
    "    df['lat1'] = df['lat'].shift(1)\n",
    "    df['lon1'] = df['lon'].shift(1)\n",
    "    df['dist'] = haversine_np(df['lon'], df['lat'], df['lon1'], df['lat1'])\n",
    "    df['time_diff'] = df['datetime'].diff()\n",
    "    df['leg_speed'] = df['dist']*1000 / df['time_diff'].dt.total_seconds() # in m/s\n",
    "    df['leg_speed_kts'] = df['leg_speed']*1.9438452\n",
    "    # df['speed_diff'] = df['leg_speed_kts'] - df['sog']\n",
    "\n",
    "    df = df.drop(columns=['lat1', 'lon1'])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def drop_err_positions(df, cutoff_speed=20, plots=False):\n",
    "\n",
    "    df2 = pd.DataFrame()\n",
    "    for ship in df.groupby('IMO'):\n",
    "        df_temp = ship[1]\n",
    "        df_temp = calc_distances(df_temp)\n",
    "        i = 0\n",
    "        df_ori = df_temp.copy()\n",
    "        max_sp = df_temp['leg_speed_kts'].max()\n",
    "        \n",
    "        while len(df_temp.loc[(df_temp['leg_speed_kts'] > cutoff_speed)]) != 0:\n",
    "            i = i + 1\n",
    "            df_temp = df_temp[df_temp['leg_speed_kts'] < cutoff_speed]\n",
    "            df_temp = calc_distances(df_temp)\n",
    "        \n",
    "        df2 = df2.append(df_temp)\n",
    "        \n",
    "        if plots:\n",
    "            if i > 0:\n",
    "                plot_wrapping(df_ori, geo_map=True)\n",
    "                plt.scatter(df_ori.lon, df_ori.lat, s=0.8, c=df_ori.datetime, alpha=0.7)\n",
    "                plt.title(f'{i} erroneous position records {max_sp}')\n",
    "            print(f'dropped {i} records')\n",
    "\n",
    "\n",
    "    return df2\n",
    "\n",
    "df2 = drop_err_positions(df, plots=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Coastline data to detect ports\n",
    "# coastlines = pd.read_csv(folder_loc + r\"\\other\\coasts.csv\")\n",
    "# coastlines = coastlines.rename(columns={'latitude': 'lat', 'longitude': 'lon'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import geopandas as gpd\n",
    "# import os\n",
    "\n",
    "# dir_path = r'C:\\Users\\Nefelie\\OneDrive - University of Southampton\\Uni\\3rd Year\\Individual Project\\other\\gshhg-shp-2.3.7\\WDBII_shp\\h'\n",
    "\n",
    "# # Get a list of all shapefiles in the directory\n",
    "# # shp_files = [f for f in os.listdir(dir_path) if f.endswith('.shp')]\n",
    "# shp_files = [f for f in os.listdir(dir_path) if f.endswith('.shp') and 'river' in f]\n",
    "# # Loop through each shapefile and extract the linestring data\n",
    "# point_data = []\n",
    "# for shp_file in shp_files:\n",
    "#     gdf = gpd.read_file(os.path.join(dir_path, shp_file))\n",
    "#     # gdf.plot()\n",
    "#     # Extract the point data from the linestrings\n",
    "#     for row in gdf.itertuples():\n",
    "#         for point in row.geometry.coords:\n",
    "#             point_data.append((point[0], point[1]))\n",
    "    \n",
    "# # Create a dataframe from the point data\n",
    "# dfaa = pd.DataFrame(point_data, columns=['longitude', 'latitude'])\n",
    "# print(len(dfaa))\n",
    "# # Write the dataframe to a CSV file\n",
    "# dfaa.to_csv(r'C:\\Users\\Nefelie\\OneDrive - University of Southampton\\Uni\\3rd Year\\Individual Project\\other\\rivers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import geopandas as gpd\n",
    "# import os\n",
    "\n",
    "# dir_path = r'C:\\Users\\Nefelie\\OneDrive - University of Southampton\\Uni\\3rd Year\\Individual Project\\other\\gshhg-shp-2.3.7\\GSHHS_shp\\h'\n",
    "\n",
    "# # Get a list of all shapefiles in the directory\n",
    "# shp_files = [f for f in os.listdir(dir_path) if f.endswith('.shp')]\n",
    "\n",
    "# # Loop through each shapefile and extract the point data\n",
    "# point_data = []\n",
    "# for shp_file in shp_files:\n",
    "#     gdf = gpd.read_file(os.path.join(dir_path, shp_file))\n",
    "#     # Extract the point data from the polygons\n",
    "#     for row in gdf.itertuples():\n",
    "#         polygon = row.geometry\n",
    "#         for point in polygon.exterior.coords:\n",
    "#             point_data.append((point[0], point[1]))\n",
    "\n",
    "# # Create a dataframe from the point data\n",
    "# dfz = pd.DataFrame(point_data, columns=['longitude', 'latitude'])\n",
    "# print(len(dfz))\n",
    "# # Write the dataframe to a CSV file\n",
    "# dfz.to_csv(r'C:\\Users\\Nefelie\\OneDrive - University of Southampton\\Uni\\3rd Year\\Individual Project\\other\\shorelines.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "max_time_dict = {}\n",
    "print(df2['datetime'].dtype)\n",
    "for i, (imo, df_temp) in enumerate(df2.groupby('IMO')):         \n",
    "    max_time = df_temp['time_diff'].dt.days.max()\n",
    "    max_time_dict[imo] = max_time\n",
    "\n",
    "plt.figure(figsize=[10, 4], dpi=400)\n",
    "x_labels = list(map(str, max_time_dict.keys())) \n",
    "y_values = list(max_time_dict.values())\n",
    "\n",
    "colors = ['grey' if y >= 10 else 'lightgrey' for y in y_values]\n",
    "\n",
    "plt.bar(x_labels, y_values, align='edge', width=0.8, color=colors)\n",
    "plt.xlabel('Ship IMO')\n",
    "plt.xlim(x_labels[0], x_labels[-1])\n",
    "plt.tick_params(axis='x', labelbottom=False)\n",
    "plt.ylabel('Maximum Time Gap (days)')\n",
    "plt.yscale('log')\n",
    "plt.axhline(y=10, color='black', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, (imo, df_temp) in enumerate(df2.groupby('IMO')):\n",
    "#     plt.figure()\n",
    "#     ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "#     ax.coastlines(linewidth=0.35)\n",
    "    \n",
    "#     plt.scatter(df_temp.lon, df_temp.lat, s=0.1, linewidth=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% SPLIT SHIPS WITH TIMEGAP INTO MULTIPLE SHIPS\n",
    "\n",
    "def split_ships(df, cutoff_time=10):\n",
    "    \"\"\"splits a ship into multiple ships if time diff between succesive records > cutoff_time (in days)\"\"\"\n",
    "\n",
    "    df2 = pd.DataFrame()\n",
    "\n",
    "    for i in df.groupby('IMO'):\n",
    "        ship = i[1]\n",
    "        cut_time = pd.Timedelta(days=cutoff_time)\n",
    "        \n",
    "        ship['mask'] = ship['time_diff'] > cut_time\n",
    "        ship['mask'] = ship['mask'].fillna(method='bfill')\n",
    "        ship['mask']= ship['mask'].astype(int)\n",
    "\n",
    "        if ship['mask'].cumsum().iloc[-1] > 0:\n",
    "            ship['IMO'] = ship['IMO'] + '_' + ship['mask'].cumsum().astype(str)\n",
    "\n",
    "        for j in ship.groupby('IMO'):\n",
    "            sub_ship = j[1]\n",
    "            sub_ship = calc_distances(sub_ship)\n",
    "            sub_ship = sub_ship.drop(columns=['mask'])\n",
    "            df2 = df2.append(sub_ship)\n",
    "\n",
    "    return df2\n",
    "\n",
    "df = split_ships(df2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ports Database"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ships Close to Coastline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Coastline data to detect ports\n",
    "# coastlines = pd.read_csv(folder_loc + r\"\\other\\coasts.csv\")\n",
    "# coastlines = coastlines.rename(columns={'latitude': 'lat', 'longitude': 'lon'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import geopandas as gpd\n",
    "# import os\n",
    "\n",
    "# dir_path = r'C:\\Users\\Nefelie\\OneDrive - University of Southampton\\Uni\\3rd Year\\Individual Project\\other\\gshhg-shp-2.3.7\\WDBII_shp\\h'\n",
    "\n",
    "# # Get a list of all shapefiles in the directory\n",
    "# # shp_files = [f for f in os.listdir(dir_path) if f.endswith('.shp')]\n",
    "# shp_files = [f for f in os.listdir(dir_path) if f.endswith('.shp') and 'river' in f]\n",
    "# # Loop through each shapefile and extract the linestring data\n",
    "# point_data = []\n",
    "# for shp_file in shp_files:\n",
    "#     gdf = gpd.read_file(os.path.join(dir_path, shp_file))\n",
    "#     # gdf.plot()\n",
    "#     # Extract the point data from the linestrings\n",
    "#     for row in gdf.itertuples():\n",
    "#         for point in row.geometry.coords:\n",
    "#             point_data.append((point[0], point[1]))\n",
    "    \n",
    "# # Create a dataframe from the point data\n",
    "# dfaa = pd.DataFrame(point_data, columns=['longitude', 'latitude'])\n",
    "# print(len(dfaa))\n",
    "# # Write the dataframe to a CSV file\n",
    "# dfaa.to_csv(r'C:\\Users\\Nefelie\\OneDrive - University of Southampton\\Uni\\3rd Year\\Individual Project\\other\\rivers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import geopandas as gpd\n",
    "# import os\n",
    "\n",
    "# dir_path = r'C:\\Users\\Nefelie\\OneDrive - University of Southampton\\Uni\\3rd Year\\Individual Project\\other\\gshhg-shp-2.3.7\\GSHHS_shp\\h'\n",
    "\n",
    "# # Get a list of all shapefiles in the directory\n",
    "# shp_files = [f for f in os.listdir(dir_path) if f.endswith('.shp')]\n",
    "\n",
    "# # Loop through each shapefile and extract the point data\n",
    "# point_data = []\n",
    "# for shp_file in shp_files:\n",
    "#     gdf = gpd.read_file(os.path.join(dir_path, shp_file))\n",
    "#     # Extract the point data from the polygons\n",
    "#     for row in gdf.itertuples():\n",
    "#         polygon = row.geometry\n",
    "#         for point in polygon.exterior.coords:\n",
    "#             point_data.append((point[0], point[1]))\n",
    "\n",
    "# # Create a dataframe from the point data\n",
    "# dfz = pd.DataFrame(point_data, columns=['longitude', 'latitude'])\n",
    "# print(len(dfz))\n",
    "# # Write the dataframe to a CSV file\n",
    "# dfz.to_csv(r'C:\\Users\\Nefelie\\OneDrive - University of Southampton\\Uni\\3rd Year\\Individual Project\\other\\shorelines.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "rivers = pd.read_csv(folder_loc + r\"\\other\\rivers.csv\")\n",
    "rivers = rivers.rename(columns={'latitude': 'lat', 'longitude': 'lon'})\n",
    "\n",
    "shorelines = pd.read_csv(folder_loc + r\"\\other\\shorelines.csv\")\n",
    "shorelines = shorelines.rename(columns={'latitude': 'lat', 'longitude': 'lon'})\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(8,8), dpi=400)\n",
    "# ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "# plt.scatter(rivers.lon, rivers.lat, s=0.005, label=\"rivers\", c=\"#008CFF\", linewidths=0.1, alpha=0.5)\n",
    "# plt.scatter(shorelines.lon, shorelines.lat, s=0.01, label=\"shorelines\", c=\"k\", linewidths=0.1)\n",
    "# ax.set_extent([-180, 180, -90, 90], crs=ccrs.PlateCarree())\n",
    "\n",
    "# gl = ax.gridlines(draw_labels=True, alpha=0.2, color=\"k\", linestyle='--', linewidth=0.5, xlocs=range(-180, 181, 90), ylocs=range(-180, 91, 45))\n",
    "# gl.top_labels = True\n",
    "# gl.right_labels = True\n",
    "# gl.xlabel_style = {'size': 8, 'color': 'k'}\n",
    "# gl.ylabel_style = {'size': 8, 'color': 'k'}\n",
    "# # plt.legend()\n",
    "# gl.xpadding = 15 \n",
    "# gl.ypadding = 10 \n",
    "\n",
    "coasts_rivers = pd.concat([shorelines, rivers], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source of first two functions: https://autogis-site.readthedocs.io/en/2020_/notebooks/L3/06_nearest-neighbor-faster.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% SHIPS CLOSE TO PORTS\n",
    "\n",
    "def get_nearest(src_points, candidates, k_neighbors=1):\n",
    "    \"\"\"Find nearest neighbors for all source points from a set of candidate points\"\"\"\n",
    "\n",
    "    # Create tree from the candidate points\n",
    "    tree = BallTree(candidates, leaf_size=15, metric='haversine') \n",
    "    # Find closest points and distances\n",
    "    distances, indices = tree.query(src_points, k=k_neighbors)\n",
    "\n",
    "    # Transpose to get distances and indices into arrays\n",
    "    distances = distances.transpose()\n",
    "    indices = indices.transpose()\n",
    "\n",
    "    # Get closest indices and distances (i.e. array at index 0)\n",
    "    closest = indices[0] # 0 for closest, 1 would be second closest\n",
    "    closest_dist = distances[0]\n",
    "\n",
    "    # Return indices and distances\n",
    "    return (closest, closest_dist)\n",
    "\n",
    "def nearest_neighbor(left_gdf, right_gdf, return_dist=True):\n",
    "    \"\"\"\n",
    "    For each point in left_gdf, find closest point in right GeoDataFrame and return them.\n",
    "    NOTICE: Assumes that the input Points are in WGS84 projection (lat/lon).\n",
    "    \"\"\"\n",
    "    \n",
    "    left_geom_col = left_gdf.geometry.name\n",
    "    right_geom_col = right_gdf.geometry.name\n",
    "    \n",
    "    # Ensure that index in right gdf is formed of sequential numbers\n",
    "    right = right_gdf.copy().reset_index(drop=True)\n",
    "\n",
    "    # Parse coordinates from points and insert them into a numpy array as RADIANS\n",
    "    left_radians = np.array(left_gdf[left_geom_col].apply(lambda geom: (geom.y * np.pi / 180, geom.x * np.pi / 180)).to_list())\n",
    "    right_radians = np.array(right[right_geom_col].apply(lambda geom: (geom.y * np.pi / 180, geom.x * np.pi / 180)).to_list())    # Find the nearest points\n",
    "    # -----------------------\n",
    "    # closest ==> index in right_gdf that corresponds to the closest point\n",
    "    # dist ==> distance between the nearest neighbors (in km)\n",
    "    \n",
    "    closest, dist = get_nearest(src_points=left_radians, candidates=right_radians)\n",
    "\n",
    "    # Return points from right GeoDataFrame that are closest to points in left GeoDataFrame\n",
    "    closest_points = right.loc[closest]\n",
    "    \n",
    "    # Ensure that the index corresponds the one in left_gdf\n",
    "    # closest_points = closest_points.reset_index(drop=True)\n",
    "    closest_points = closest_points.set_index(left_gdf.index)\n",
    "    if return_dist:\n",
    "        # Convert to meters from radians\n",
    "        earth_radius = 6371.0088  # km\n",
    "        closest_points['distance'] = dist * earth_radius\n",
    "        \n",
    "    return closest_points\n",
    "\n",
    "\n",
    "def create_geodf(df):\n",
    "    \"\"\"create a geodataframe from a dataframe\"\"\"\n",
    "    geom = gpd.points_from_xy(df.lon, df.lat, crs=\"EPSG:4326\")\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=geom)    \n",
    "    return gdf\n",
    "\n",
    "def get_nn_df(df_main, df_comp, keep_id=False, id='id', id_col=False):\n",
    "    \"\"\"returns df with additional columns:\n",
    "        - the closest data point to another dataframe, df_comp\n",
    "        - its respective distance\"\"\"\n",
    "\n",
    "    gdf_main = create_geodf(df_main)\n",
    "    gdf_comp =  create_geodf(df_comp)\n",
    "\n",
    "    # FIND CLOSEST PORT FOR EACH AIS SIGNAL\n",
    "    closest_geom = nearest_neighbor(gdf_main, gdf_comp, return_dist=True) \n",
    "    closest_geom = closest_geom.set_index(df_main.index)\n",
    "    if id_col:\n",
    "        closest_geom = closest_geom.rename(columns={'geometry': 'closest_geom', id: f'closest_{id}'})\n",
    "    else:\n",
    "        closest_geom = closest_geom.rename(columns={'geometry': 'closest_geom'})\n",
    "\n",
    "    if keep_id:\n",
    "        try:\n",
    "            closest_geom = closest_geom[[f'closest_{id}','closest_geom', 'distance']]\n",
    "        except:\n",
    "            closest_geom = closest_geom[[id, 'closest_geom', 'distance']]\n",
    "    else:\n",
    "        closest_geom = closest_geom[['closest_geom', 'distance']]\n",
    "    # joined dataframes\n",
    "    df_closest_geom = gdf_main.join(closest_geom).copy()\n",
    "    df_closest_geom = df_closest_geom.set_index(df_main.index)\n",
    "\n",
    "    return df_closest_geom\n",
    "\n",
    "\n",
    "def get_df_within_dist(df_main, df_comp, within_dist, keep_id=False, id='id', id_col=False):\n",
    "    \"\"\"Returns a dataframe of the rows in df_main within_dist (km) of a second dataframe df_comp\"\"\"\n",
    "\n",
    "    df_closest_geom = get_nn_df(df_main, df_comp, keep_id, id, id_col)\n",
    "    # only retain ships within certain km of a port\n",
    "    gdf_df_near_geom = df_closest_geom.loc[df_closest_geom['distance'] < within_dist] # distance in km\n",
    "  \n",
    "    # gdf_df_near_geom = gdf_df_near_geom.drop(columns=[\"geometry\", \"closest_geom\"])\n",
    "    gdf_df_near_geom = gdf_df_near_geom.drop(columns=[\"geometry\", \"closest_geom\", \"distance\"])\n",
    "\n",
    "    return gdf_df_near_geom\n",
    "\n",
    "df_slow = df[df.sog < 1] # slow ships (below 1kts)\n",
    "ships_in_port = get_df_within_dist(df_slow, coasts_rivers, within_dist=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from shapely.geometry import LineString\n",
    "\n",
    "# # Create a link (LineString) between building and stop points\n",
    "\n",
    "# ships_in_port['link'] = ships_in_port.apply(lambda row: LineString([row['geometry'], row['closest_geom']]), axis=1)\n",
    "\n",
    "# # Set link as the active geometry\n",
    "# ship_links = ships_in_port.copy()\n",
    "# ship_links = ship_links.set_geometry('link')\n",
    "\n",
    "# plt.figure()\n",
    "# ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "# # Plot the connecting links between ships and ports and color them based on distance\n",
    "# ship_links.plot(ax=ax, column='distance', cmap='Blues', scheme='quantiles', k=4, alpha=0.8, lw=1)\n",
    "# ships_in_port.plot(ax=ax, color='blue', markersize=8, alpha=0.7)\n",
    "# ax.scatter(coastlines.lon, coastlines.lat, c=\"gray\", label=\"Coastline\", s=8, linewidth=0.1)\n",
    "\n",
    "# # coasts_rivers.plot(ax=ax, markersize=4, marker='o', color='red', alpha=0.9, zorder=3)\n",
    "\n",
    "# # Zoom closer\n",
    "# ax.set_xlim([-180, 180])\n",
    "# ax.set_ylim([-90, 90])\n",
    "# plt.title(\"Nearest Neighbours\")\n",
    "# # Set map background color to black, which helps with contrast\n",
    "# # ax.set_facecolor('black')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ships in Port Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(6,6), dpi=400)\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "# ax.coastlines()\n",
    "ax.add_feature(cfeature.LAND)\n",
    "ax.add_feature(cfeature.OCEAN)\n",
    "ax.add_feature(cfeature.RIVERS, linewidth=0.4)\n",
    "ax.add_feature(cfeature.BORDERS, linewidth=0.2, color=\"gray\")\n",
    "gl = ax.gridlines(draw_labels=True, alpha=0.2, color=\"k\", linestyle='--', linewidth=0.3, xlocs=range(-180, 180, 45), ylocs=range(-90, 90, 45))\n",
    "# # ax.coastlines()\n",
    "gl.top_labels = False\n",
    "gl.right_labels = False\n",
    "gl.xlabel_style = {'size': 8, 'color': 'k'}\n",
    "gl.ylabel_style = {'size': 8, 'color': 'k'}\n",
    "gl.xpadding = 15 \n",
    "gl.ypadding = 10 \n",
    "\n",
    "plt.scatter(x=df.lon, y=df.lat, s=0.05, c=\"black\", label=\"Ship Route\", zorder=3, alpha=0.5, linewidth=0.01)\n",
    "plt.scatter(x=df_slow.lon, y=df_slow.lat, s=1, c='tab:red', label=\"Stationary Ship\", zorder=4, linewidth=0.1)\n",
    "plt.scatter(x=ships_in_port.lon, y=ships_in_port.lat, s=1, c=\"limegreen\", label=\"Ship in Port\", zorder=5, linewidth=0.1)\n",
    "plt.legend(loc='upper center',bbox_to_anchor=(0.7,0.1), markerscale=5, ncol=3, prop={'size': 6}, frameon=False)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ships in Port Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% PLOTTING SHIPS IN PORT\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=[4,4], dpi=400)\n",
    "\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.set_extent([130, 140, -18, -7], crs=ccrs.PlateCarree())\n",
    "\n",
    "ax.coastlines(linewidth=0.35)\n",
    "ax.add_feature(cfeature.LAND)\n",
    "ax.add_feature(cfeature.OCEAN)\n",
    "# ax.add_feature(cfeature.BORDERS, linestyle='-', alpha=.5, linewidth=0.5)\n",
    "ax.add_feature(cfeature.LAKES, alpha=0.95)\n",
    "\n",
    "# plt.scatter(x=coastlines.lon, y=coastlines.lat, s=0.1, c=\"k\", label=\"Coastline\", zorder=5)\n",
    "plt.scatter(x=df.lon, y=df.lat, s=2, c=\"black\", label=\"Ship route\", zorder=3, linewidths=0.1, alpha=0.5)\n",
    "plt.scatter(x=df_slow.lon, y=df_slow.lat, s=30, c='tab:red', label=\"Stationary ship\", zorder=4, linewidths=0.1)\n",
    "plt.scatter(x=ships_in_port.lon, y=ships_in_port.lat, s=30, c=\"orange\", label=\"Ship near coast\", zorder=5, linewidths=0.1)\n",
    "\n",
    "plt.legend(loc='lower left', markerscale=2, prop={'size': 10}, frameon=False, handletextpad=0.01, labelspacing=0.6, bbox_to_anchor=(-0.05, 0))\n",
    "# plt.legend(loc='upper center',bbox_to_anchor=(0.5,0.08), markerscale=2, ncol=3, prop={'size': 6}, frameon=False)\n",
    "gl = ax.gridlines(draw_labels=True, alpha=0.3, color=\"k\", linestyle='--', linewidth=0.8, xlocs=range(130, 150, 5), ylocs=range(-20, -7, 5))\n",
    "gl.xpadding = 20 \n",
    "gl.ypadding = 20 \n",
    "gl.top_labels = False\n",
    "gl.right_labels = False\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% PLOTTING SHIPS IN PORT\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=[4, 4], dpi=400)\n",
    "\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.set_extent([48, 58, 22, 28], crs=ccrs.PlateCarree())\n",
    "\n",
    "ax.coastlines(linewidth=0.35)\n",
    "ax.add_feature(cfeature.LAND)\n",
    "ax.add_feature(cfeature.OCEAN)\n",
    "ax.add_feature(cfeature.LAKES, alpha=0.95)\n",
    "\n",
    "plt.scatter(x=df.lon, y=df.lat, s=2, c=\"black\", label=\"Ship route\", zorder=3, linewidths=0.1, alpha=0.5)\n",
    "plt.scatter(x=df_slow.lon, y=df_slow.lat, s=6, c='tab:red', label=\"Stationary ship\", zorder=4, linewidths=0.1)\n",
    "plt.scatter(x=ships_in_port.lon, y=ships_in_port.lat, s=20, c=\"orange\", label=\"Ship near coast\", zorder=5, linewidths=0.1)\n",
    "\n",
    "plt.legend(loc='lower left', markerscale=2, prop={'size': 10}, frameon=False, handletextpad=0.01, labelspacing=0.4, bbox_to_anchor=(-0.05, 0))\n",
    "gl = ax.gridlines(draw_labels=True, alpha=0.3, color=\"k\", linestyle='--', linewidth=0.8, xlocs=range(48, 58, 4), ylocs=range(22, 28, 2))\n",
    "gl.xpadding = 20 \n",
    "gl.ypadding = 20 \n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DBSCAN Clustering Ships near coast to form Ports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_coords(df):\n",
    "    \"\"\"gets the latitude and longitude data from a dataframe and returns it as a numpy array\"\"\"\n",
    "    df_coords = pd.DataFrame()\n",
    "    df_coords[\"lat\"] = df.lat\n",
    "    df_coords[\"lon\"] = df.lon\n",
    "    np_coords = df_coords.values\n",
    "\n",
    "    return np_coords\n",
    "\n",
    "port_coords = extract_coords(ships_in_port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neighbors = NearestNeighbors(n_neighbors=2)\n",
    "# neighbors_fit = neighbors.fit(port_coords)\n",
    "# distances, indices = neighbors_fit.kneighbors(port_coords)\n",
    "\n",
    "# distances = np.sort(distances, axis=0)\n",
    "# distances = distances[:,1]\n",
    "\n",
    "\n",
    "# i = np.arange(len(distances))\n",
    "# knee = KneeLocator(i, distances, S=1, curve='convex', direction='increasing', interp_method='polynomial')\n",
    "\n",
    "# fig = plt.figure(figsize=(5, 5))\n",
    "# knee.plot_knee()\n",
    "# plt.xlabel(\"Points\")\n",
    "# plt.ylabel(\"Distance\")\n",
    "\n",
    "# opt_eps = distances[knee.knee]\n",
    "# print(opt_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = gpd.read_file(r'C:\\Users\\Nefelie\\OneDrive - University of Southampton\\Uni\\3rd Year\\Individual Project\\other\\World_Port_Index\\World_Port_Index.shp')\n",
    "# import scipy\n",
    "# from scipy.spatial import cKDTree\n",
    "# Build kdtree\n",
    "# coordinates = np.radians(data[['LATITUDE', 'LONGITUDE']])\n",
    "# kdtree = cKDTree(coordinates)\n",
    "\n",
    "# # Query kdtree for closest points\n",
    "# distances_degrees, indexes = kdtree.query(coordinates, k=2)\n",
    "\n",
    "# R = 6371.0088  # earth's radius in km\n",
    "# distances_km = 2 * R * np.sin(distances_degrees[:, 1] / 2)\n",
    "\n",
    "# new_df = data.assign(ClosestID=data['FID'][indexes[:, 1]].values, ClosestDist=distances_km)\n",
    "# zz = new_df.ClosestDist.unique()\n",
    "# pct = sum(zz > 5) / len(zz) * 100\n",
    "\n",
    "# print(f\"{100-pct:.2f}% less than 5km\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " adapted from https://stackoverflow.com/questions/67968952/how-to-calculate-distance-of-coordinates-and-categorical-dataset-with-dbscan-alg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% CLUSTER SHIPS DETECTED IN PORTS\n",
    "def get_centermost_point(cluster): \n",
    "    \"calculates the centroid of a cluster\"\n",
    "    # https://gis.stackexchange.com/questions/379042/getting-the-center-point-of-a-cluster-in-pandas\n",
    "    centroid = (MultiPoint(cluster).centroid.x, MultiPoint(cluster).centroid.y)\n",
    "    centermost_point = min(cluster, key=lambda point: great_circle(point, centroid).m)\n",
    "    return tuple(centermost_point)\n",
    "\n",
    "\n",
    "def DBSCAN_km(coords, km=10, min_points=2, labels=False):\n",
    "    \"\"\"returns a dataframe of cluster coordinates and cluster ids formed by DBSCAN\"\"\"\n",
    "    db = DBSCAN(eps=km/6371.0088, min_samples=min_points, algorithm='ball_tree', metric='haversine').fit(np.radians(coords))\n",
    "    cluster_labels = db.labels_\n",
    "    num_clusters = len(set(cluster_labels))\n",
    "    clusters = pd.DataFrame([coords[cluster_labels == n] for n in range(num_clusters)], columns = ['value'])\n",
    "    clusters['Length'] = clusters.value.apply(lambda x: len(x))\n",
    "    clusters = clusters[clusters.Length > 0]\n",
    "    clusters = clusters['value']\n",
    "\n",
    "    centermost_points = clusters.map(get_centermost_point)\n",
    "    lats, lons = zip(*centermost_points)\n",
    "    rep_points = pd.DataFrame({'lat':lats, 'lon':lons})\n",
    "    \n",
    "    coords_clustered = np.apply_along_axis(lambda row: coords[(coords[:,0]==row[0]) & (coords[:,1]==row[1])][0], axis=1, arr=rep_points)\n",
    "    coords_clustered = pd.DataFrame(coords_clustered, columns=['lat', 'lon'])\n",
    "    coords_clustered = coords_clustered.reset_index(drop=True) \n",
    "    coords_clustered.index += 1 # start index from 1\n",
    "    coords_clustered['port_id'] = coords_clustered.index\n",
    "\n",
    "    cmap = plt.cm.get_cmap('turbo', num_clusters)\n",
    "    colors = cmap(cluster_labels)\n",
    "    \n",
    "\n",
    "    if labels:\n",
    "        return coords_clustered, cluster_labels\n",
    "\n",
    "    else:\n",
    "        return coords_clustered\n",
    "\n",
    "ports_clustered, ports_labels = DBSCAN_km(port_coords, km=20, min_points=2, labels=True)\n",
    "ships_in_port_cluster = get_df_within_dist(ships_in_port, ports_clustered, within_dist=10, keep_id=True, id='port_id')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting DBSCAN Port Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(4,4), dpi=400)\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "# ax.coastlines()\n",
    "ax.add_feature(cfeature.LAND, facecolor=\"lightgrey\")\n",
    "gl = ax.gridlines(draw_labels=True, alpha=0.2, color=\"k\", linestyle='--', linewidth=0.3, xlocs=range(-180, 180, 2), ylocs=range(-90, 90, 2))\n",
    "# # ax.coastlines()\n",
    "gl.top_labels = False\n",
    "gl.right_labels = False\n",
    "gl.xlabel_style = {'size': 8, 'color': 'k'}\n",
    "gl.ylabel_style = {'size': 8, 'color': 'k'}\n",
    "gl.xpadding = 15 \n",
    "gl.ypadding = 10 \n",
    "\n",
    "\n",
    "region = \"CH\"\n",
    "if region == \"CH\":\n",
    "    # ax.set_extent([117, 136, 32, 44], crs=ccrs.PlateCarree())\n",
    "    ax.set_extent([118, 122.1, 37, 40], crs=ccrs.PlateCarree())\n",
    "\n",
    "elif region ==\"EU\":\n",
    "    ax.set_extent([-5, 20, 40, 70], crs=ccrs.PlateCarree())\n",
    "elif region == \"US\":\n",
    "    ax.set_extent([-170, -45, 0, 70], crs=ccrs.PlateCarree())\n",
    "elif region == \"ME\":\n",
    "    ax.set_extent([20, 100, -45, 40], crs=ccrs.PlateCarree())\n",
    "elif region == \"AF\":\n",
    "    ax.set_extent([-20, 60, -45, 40], crs=ccrs.PlateCarree())\n",
    "\n",
    "\n",
    "for label in np.unique(ports_labels):\n",
    "    mask = (ports_labels == label)\n",
    "    x = port_coords[:, 1][mask]\n",
    "    y = port_coords[:, 0][mask]\n",
    "\n",
    "    if label == -1: # ignore -1 labels (noise)\n",
    "        plt.scatter(x, y, s=8, c=\"lightgrey\")\n",
    "\n",
    "    else:\n",
    "        plt.scatter(x, y, s=20)\n",
    "\n",
    "plt.scatter(ports_clustered.lon, ports_clustered.lat, c=\"k\", s=20, marker=\"x\", linewidth=1.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(6,6), dpi=400)\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "# ax.coastlines()\n",
    "ax.add_feature(cfeature.LAND)\n",
    "ax.add_feature(cfeature.OCEAN)\n",
    "ax.add_feature(cfeature.RIVERS, linewidth=0.4)\n",
    "ax.add_feature(cfeature.BORDERS, linewidth=0.2, color=\"gray\")\n",
    "gl = ax.gridlines(draw_labels=True, alpha=0.2, color=\"k\", linestyle='--', linewidth=0.3, xlocs=range(-180, 180, 45), ylocs=range(-90, 90, 45))\n",
    "# # ax.coastlines()\n",
    "gl.top_labels = False\n",
    "gl.right_labels = False\n",
    "gl.xlabel_style = {'size': 8, 'color': 'k'}\n",
    "gl.ylabel_style = {'size': 8, 'color': 'k'}\n",
    "gl.xpadding = 15 \n",
    "gl.ypadding = 10 \n",
    "\n",
    "\n",
    "rs_scatter = ax.scatter(ports_clustered['lon'], ports_clustered['lat'], c='k', s=0.5, zorder=1, transform=ccrs.PlateCarree())\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ship Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe for each Ship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Dataframe of Dataframes for Ship Data\n",
    "\n",
    "def remove_duplicates(arr):\n",
    "    result = np.array([next(g) for k, g in groupby(arr)])\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_status(row):\n",
    "    #returns S if a vessel is \"moored/anchored/stopped\" but not inside a port\n",
    "    if row['dist'] < 0.1 and row['sog'] < 1 and pd.isna(row['port_id']):\n",
    "        return 'A' # anchored\n",
    "    else:\n",
    "        return 'S' # sailing\n",
    "\n",
    "\n",
    "ships_to_append = []\n",
    "ports_to_append = []\n",
    "df_ports = pd.DataFrame()\n",
    "\n",
    "\n",
    "def add_common_index(df_to_edit, df_to_compare, col_name=\"port_id\", main_col_name=\"port_id\"):\n",
    "    common_index = df_to_compare.index.intersection(df_to_edit.index)\n",
    "    df_to_edit.loc[common_index, main_col_name] = df_to_compare.loc[common_index, col_name] # port_id ship is in (only populated if ship is in a port)\n",
    "\n",
    "    return df_to_edit\n",
    "\n",
    "\n",
    "# loop through df to determine where ships are in relation to ports\n",
    "for i, (imo, df_temp) in enumerate(df.groupby('IMO')):\n",
    "    total_dist = df_temp['dist'].cumsum().max()\n",
    "\n",
    "    #------------------------Add Port ID if Ship is in Port------------------\n",
    "    df_temp = add_common_index(df_temp, ships_in_port_cluster, col_name=\"port_id\")\n",
    "\n",
    "    #------------------ ASSIGN CLOSEST PORT TO ANCHORED SHIPS----------------\n",
    "    df_temp['status'] = df_temp.apply(get_status, axis=1)\n",
    "       \n",
    "    # get nearest port to status\n",
    "    df_anchor = df_temp[df_temp['status'] == 'A']\n",
    "\n",
    "    if len(df_anchor) > 0:\n",
    "        ships_moored = get_df_within_dist(df_anchor, ports_clustered, within_dist=80, keep_id=True, id=\"port_id\", id_col=True)\n",
    "        df_temp = add_common_index(df_temp, ships_moored, col_name=\"closest_port_id\", main_col_name=\"port_id\")\n",
    "        \n",
    "    #------------------ CREATE BETW_PORT COLUMN -----------------------------\n",
    "    df_temp[\"port_id_fwd\"] = df_temp[\"port_id\"].ffill() # replace following nans with current port id\n",
    "    df_temp[\"port_id_bwd\"] = df_temp[\"port_id\"].bfill() # replace previous nans with current port id\n",
    "    df_temp[\"subtract1\"] = df_temp[\"port_id_bwd\"] - df_temp[\"port_id\"] # returns 0 if ship is in port, nan if not in port\n",
    "    df_temp[\"subtract1\"]  = df_temp[\"subtract1\"].replace(np.NaN, 1) # if not in port, replace with 1\n",
    "    df_temp[\"subtract1\"]  = df_temp[\"subtract1\"].replace(0, np.NaN) # if in port, replace with 0\n",
    "    df_temp[\"from_port\"] = df_temp[\"port_id_fwd\"] * df_temp[\"subtract1\"]\n",
    "    df_temp[\"to_port\"] = df_temp[\"port_id_bwd\"] * df_temp[\"subtract1\"]\n",
    "    df_temp[\"betw_port\"] = (list(zip(df_temp[\"from_port\"], df_temp[\"to_port\"])))\n",
    "    \n",
    "    # replace nan values for port with tuple of port id it is in\n",
    "    df_temp['betw_port'] = np.where(df_temp['betw_port'].apply(lambda x: pd.isna(x[0]) and pd.isna(x[1])),  # condition\n",
    "                                    df_temp['port_id'].apply(lambda x: (x, x)),  # new value\n",
    "                                    df_temp['betw_port'])  # existing value\n",
    "    \n",
    "    df_temp = df_temp.drop(columns=[\"subtract1\", \"port_id_fwd\", \"port_id_bwd\", \"from_port\", \"to_port\"])\n",
    "    \n",
    "    ports_visited = remove_duplicates(df_temp.sort_values(\"datetime\").dropna().port_id.values)  \n",
    "\n",
    "    #-------------- DELETE FIRST AND LAST SEGMENTS IF NOT IN PORT--------------\n",
    "    # find the indices of the first and last non-null port_id\n",
    "    first_non_nan = df_temp['port_id'].first_valid_index()\n",
    "    last_non_nan = df_temp['port_id'].last_valid_index()\n",
    "    if first_non_nan != None:\n",
    "        df_temp = df_temp.loc[first_non_nan:last_non_nan]    \n",
    "        \n",
    "        #-----------------------------APPENDING------------------------------------\n",
    "        # df_temp = df_temp.drop(columns=[\"dist\"])\n",
    "\n",
    "        record = {'IMO': imo, 'data': df_temp, 'total_dist': total_dist, 'ports_visited': ports_visited}\n",
    "        ships_to_append.append(record)\n",
    "        \n",
    "        ports_seq = [(ports_visited[i], ports_visited[i+1]) for i in range(len(ports_visited)-1)]\n",
    "        port_record = {\"sequence\": ports_seq, \"IMO\": imo}\n",
    "        ports_to_append.append(port_record)\n",
    "        \n",
    "        df_ports = df_ports.append(df_temp)\n",
    "            \n",
    "                     \n",
    "df_ships = pd.DataFrame.from_records(ships_to_append, index='IMO')  \n",
    "port_sequences = pd.DataFrame.from_records(ports_to_append)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Port to Port Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% PORT-PORT SEQUENCES\n",
    "\n",
    "def sequence_to_counter(df):\n",
    "    \"\"\"Takes as an input a dataframe of an array of tuples (e.g. [(1, 2), (2, 3)...])\n",
    "    and returns a dataframe with the number of times a tuple combination occurs\n",
    "    and a counter for each element within the tuple\n",
    "    \"\"\"\n",
    "\n",
    "    # list of all port-to-port combinations\n",
    "    tuple_list = [tup for sublist in df['sequence'] for tup in sublist]\n",
    "    \n",
    "    # number of occurrences of each port-to-port combination\n",
    "    combs_counter = Counter(tuple_list)\n",
    "    \n",
    "    item_counter = df['sequence'].tolist()\n",
    "    item_counter = list(chain.from_iterable(item_counter))\n",
    "    item_counter = [value for tup in item_counter for value in tup]\n",
    "    item_counter = Counter(item_counter)\n",
    "    \n",
    "    # total number of times a ship has visited the port (includes times when a ship has visited it multiple times a year)\n",
    "    item_counter = dict(item_counter.most_common())\n",
    "    \n",
    "    return combs_counter, item_counter\n",
    "\n",
    "\n",
    "port_comb_counts, most_common_ports = sequence_to_counter(port_sequences)\n",
    "ports_clustered['no_ships_visited'] = pd.Series(most_common_ports)\n",
    "\n",
    "# port-to-port sequences stats\n",
    "port_to_port = pd.DataFrame([port_comb_counts]).transpose()\n",
    "port_to_port.rename(columns={0:'no_times'},inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepping Data for Graph"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot RDP wrapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_cross_track(latA, lonA, latB, lonB, latP, lonP):\n",
    "    \"\"\"Returns the shortest distance(km) between an arc AB \n",
    "       and a point in question P. \n",
    "    \"\"\"\n",
    "\n",
    "    latA, lonA, latB, lonB, latP, lonP = map(np.radians, [latA, lonA, latB, lonB, latP, lonP])\n",
    "\n",
    "    R = 6371.0088  # Earth radius in km\n",
    "\n",
    "    bngAB = bng(latA, lonA, latB, lonB)\n",
    "    bngAC = bng(latA, lonA, latP, lonP)\n",
    "    distAP = haversine_np(lonA, latA, lonP, latP, in_deg=False)\n",
    "\n",
    "    diff = abs(bngAC - bngAB)\n",
    "    if diff > math.pi:\n",
    "        diff = 2 * math.pi - diff\n",
    "    # Is relative bearing obtuse?\n",
    "    if diff > (math.pi/2):\n",
    "        d = distAP\n",
    "    else:\n",
    "        # Find the cross-track distance.\n",
    "        d_temp = math.asin(math.sin(distAP/R) * math.sin(bngAC - bngAB)) * R\n",
    "\n",
    "        # Is p4 beyond the arc?\n",
    "        distAB = haversine_np(lonA, latA, lonB, latB, in_deg=False)\n",
    "        distAI = math.acos(math.cos(distAP/R) / math.cos(d_temp/R)) * R # I is the point of intersection on great circle\n",
    "        if distAI > distAB:\n",
    "            d = haversine_np(lonB, latB, lonP,  latP, in_deg=False)\n",
    "        else:\n",
    "            d = abs(d_temp)\n",
    "\n",
    "    return d\n",
    "\n",
    "\n",
    "def bng(latA, lonA, latB, lonB):\n",
    "    # Returns the bearing from one lat/lon point in radians to another\n",
    "    b = math.atan2(math.sin(lonB - lonA) * math.cos(latB),\n",
    "                   math.cos(latA) * math.sin(latB) - math.sin(latA) * math.cos(latB) * math.cos(lonB - lonA))\n",
    "    return b\n",
    "\n",
    "\n",
    "def rdp_idxs(input, epsilon, dist=d_cross_track):\n",
    "    \"\"\"\n",
    "    Simplifies a given array of points.\n",
    "    \"\"\"\n",
    "    dmax = 0.0\n",
    "    index = -1\n",
    "\n",
    "    for i in range(1, len(input)):\n",
    "        d = dist(*input[0], *input[-1], *input[i])\n",
    "\n",
    "        if d > dmax:\n",
    "            index = i\n",
    "            dmax = d\n",
    "\n",
    "    if dmax > epsilon:\n",
    "        idx_st1 = rdp_idxs(input[:index + 1], epsilon, dist) # sub track 1 index\n",
    "        idx_st2 = rdp_idxs(input[index:], epsilon, dist)     # sub track 2 index\n",
    "        \n",
    "        # Add the index of the last point of r1 to r2, since they are neighbors\n",
    "        idx_st2 = [x + index for x in idx_st2]\n",
    "\n",
    "        return idx_st1[:-1] + idx_st2\n",
    "    else:\n",
    "        return [0, len(input) - 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wrapping2(df):\n",
    "    # Convert longitudes greater than 180 to negative values\n",
    "    df.loc[df['lon'] > 180, 'lon'] -= 360\n",
    "    # Convert longitudes less than -180 to positive values\n",
    "    df.loc[df['lon'] < -180, 'lon'] += 360\n",
    "    x, y = df['lon'], df['lat']\n",
    "    # split the track into segments that dont cross the dateline\n",
    "    xdiff = np.diff(x)\n",
    "    wrapidx = np.where(np.abs(xdiff) > 180)[0] + 1\n",
    "    segments = np.split(df, wrapidx)\n",
    "    \n",
    "    # Get a colormap object\n",
    "    cmap = plt.get_cmap('hsv')\n",
    "    \n",
    "    # Plot each segment separately\n",
    "    for i, seg in enumerate(segments):\n",
    "        x, y = seg['lon'], seg['lat']\n",
    "        IMO = seg['IMO'].iloc[0] # get the value of 'IMO' for this segment\n",
    "        color_index = hash(str(IMO)) % 256 # generate a unique color index based on IMO value\n",
    "        color = cmap(color_index / 256) # get the color for this index\n",
    "        plt.plot(x, y, linewidth=0.1, transform=ccrs.Geodetic(), c=\"k\", zorder=1)\n",
    "        # plt.scatter(df.lon, df.lat, marker=\"x\", c=\"k\", s=3, linewidth=0.4, zorder=3)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ramer-Douglas-Peuker Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "rdp_ships_list = []\n",
    "ship_data_list = []\n",
    "df_rdp = pd.DataFrame()\n",
    "ship_data_dict = {}\n",
    "\n",
    "plt.figure(figsize=(6,6), dpi=400)\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.add_feature(cfeature.LAND, facecolor=\"lightgrey\")\n",
    "gl = ax.gridlines(draw_labels=True, alpha=0.2, color=\"k\", linestyle='--', linewidth=0.3, xlocs=range(-180, 180, 45), ylocs=range(-90, 90, 45))\n",
    "# # ax.coastlines()\n",
    "gl.top_labels = False\n",
    "gl.right_labels = False\n",
    "gl.xlabel_style = {'size': 8, 'color': 'k'}\n",
    "gl.ylabel_style = {'size': 8, 'color': 'k'}\n",
    "gl.xpadding = 15 \n",
    "gl.ypadding = 10 \n",
    "\n",
    "\n",
    "for imo, row in df_ships.iterrows():\n",
    "    # print(imo)\n",
    "    row_group = row[\"data\"].sort_values(['IMO', \"datetime\"])\n",
    "        \n",
    "    # group same set of betw_port\n",
    "    row_group['betw_port_group'] = ((row_group['betw_port'] != row_group['betw_port'].shift()) |\n",
    "                              (row_group['betw_port'] == -1) |\n",
    "                              (row_group['betw_port'].shift() == -1)).cumsum()\n",
    "   \n",
    "    ship_df = pd.DataFrame()\n",
    "\n",
    "    for i, group in row_group.groupby(\"betw_port_group\"):\n",
    "        \n",
    "        # dont apply rdp if ship is in port\n",
    "        if group[\"port_id\"].notnull().all():\n",
    "        \n",
    "            if len(group) > 1:\n",
    "                # keep only the first and last rows\n",
    "                group = group.iloc[[0, -1], :]\n",
    "                ship_df = pd.concat([ship_df, group], ignore_index=True)\n",
    "                rdp_ships_list.append(group[[\"lat\", \"lon\"]]) # for clustering\n",
    "\n",
    "            else:\n",
    "                ship_df = pd.concat([ship_df, group], ignore_index=True)\n",
    "                rdp_ships_list.append(group[[\"lat\", \"lon\"]]) # for clustering\n",
    "\n",
    "\n",
    "        else: # apply rdp if not in port\n",
    "            ais_data_coords = group[[\"lat\", \"lon\"]]\n",
    "            # rdp_indices = rdp_mod(ais_data_coords.to_numpy(), epsilon=0.08) # run rdp algorithm\n",
    "            eps = 10\n",
    "            rdp_indices = rdp_idxs(ais_data_coords.to_numpy(), epsilon=eps) # run rdp algorithm\n",
    "\n",
    "            rdp_data = group.iloc[rdp_indices]\n",
    "            ship_df = pd.concat([ship_df, rdp_data], ignore_index=True)\n",
    "            rdp_ships_list.append(rdp_data[[\"lat\", \"lon\"]]) # for clustering\n",
    "            # plot_wrapping2(rdp_data)\n",
    "            # plt.scatter(rdp_data.lon, rdp_data.lat, s=0.4, linewidth=0.1, c=\"k\", zorder=2)\n",
    "            # plt.scatter(ais_data_coords.lon, ais_data_coords.lat, s=2, zorder=1)\n",
    "\n",
    "\n",
    "    ship_data_dict[imo] = ship_df\n",
    "    \n",
    "df_rdp = pd.DataFrame.from_dict(ship_data_dict, orient='index')\n",
    "df_rdp = df_rdp.rename(columns={0: 'data'})\n",
    "# plt.title(eps)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdp_all_list = np.concatenate(rdp_ships_list)\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "# ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "# ax.scatter(rdp_all_list[:, 1], rdp_all_list[:, 0], s=0.5, c=\"k\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering RDP Points to form Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdp_all_list = np.concatenate(rdp_ships_list)\n",
    "# neighbors = NearestNeighbors(n_neighbors=2)\n",
    "# neighbors_fit = neighbors.fit(rdp_all_list)\n",
    "# distances, indices = neighbors_fit.kneighbors(rdp_all_list)\n",
    "\n",
    "# distances = np.sort(distances, axis=0)\n",
    "# distances = distances[:,1]\n",
    "\n",
    "# i = np.arange(len(distances))\n",
    "# knee = KneeLocator(i, distances, S=1, curve='convex', direction='increasing', interp_method='polynomial')\n",
    "\n",
    "# knee.plot_knee(figsize=(4, 4))\n",
    "# plt.xlabel(\"Points\")\n",
    "# plt.ylabel(\"Distance\")\n",
    "\n",
    "# opt_eps = distances[knee.knee]\n",
    "# print(opt_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # rdp_all_list = np.concatenate(rdp_ships_list)\n",
    "\n",
    "# # cluster RDP points using DBSCAN\n",
    "# eps = 0.14\n",
    "# min_samples = 3\n",
    "\n",
    "# # dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "# # dbscan = DBSCAN(eps=0.18, min_samples=3)\n",
    "\n",
    "# # dbscan = DBSCAN(eps=opt_eps, min_samples=3)\n",
    "\n",
    "# eps = 0.18\n",
    "# min_samples = 20\n",
    "\n",
    "# # dbscan = DBSCAN(eps=0.2, min_samples=3)\n",
    "# dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "\n",
    "\n",
    "# labels = dbscan.fit_predict(rdp_all_list)\n",
    "\n",
    "# # ------------------------- Centroid of Cluster -------------------------------\n",
    "\n",
    "# num_clusters = len(set(labels))\n",
    "# clusters = pd.DataFrame([rdp_all_list[labels == n] for n in range(num_clusters)], columns = ['value'])\n",
    "# clusters['Length'] = clusters.value.apply(lambda x: len(x))\n",
    "# clusters = clusters[clusters.Length > 0]\n",
    "# clusters = clusters['value']\n",
    "# centermost_points_1 = clusters.map(get_centermost_point)\n",
    "\n",
    "# lats, lons = zip(*centermost_points_1)\n",
    "# intermediary_nodes = pd.DataFrame({'lat':lats, 'lon':lons})\n",
    "# intermediary_nodes[\"node_id\"] =  [n for n in range(num_clusters-1)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # rdp_all_list = np.concatenate(rdp_ships_list)\n",
    "# # # nodes_clustered, node_labels = DBSCAN_km(rdp_all_list, km=10, min_points=10, labels=True)\n",
    "\n",
    "# # #%% PLOTTING DBSCAN\n",
    "\n",
    "# plt.figure(figsize=(5,5), dpi=400)\n",
    "# ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "\n",
    "# region = \"CH\"\n",
    "\n",
    "# if region == \"CH\":\n",
    "#     ax.set_extent([80, 160, -30, 50], crs=ccrs.PlateCarree())\n",
    "# elif region ==\"EU\":\n",
    "#     ax.set_extent([-20, 50, 20, 75], crs=ccrs.PlateCarree())\n",
    "# elif region == \"US\":\n",
    "#     ax.set_extent([-170, -45, 0, 70], crs=ccrs.PlateCarree())\n",
    "# elif region == \"ME\":\n",
    "#     ax.set_extent([20, 100, -45, 40], crs=ccrs.PlateCarree())\n",
    "# elif region == \"AF\":\n",
    "#     ax.set_extent([-20, 60, -45, 40], crs=ccrs.PlateCarree())\n",
    "\n",
    "\n",
    "# ax.add_feature(cfeature.LAND, facecolor=\"lightgrey\")\n",
    "\n",
    "# for label in np.unique(labels):\n",
    "#     mask = (labels == label)\n",
    "#     x = rdp_all_list[:, 1][mask]\n",
    "#     y = rdp_all_list[:, 0][mask]\n",
    "\n",
    "#     if label == -1: # ignore -1 labels (noise)\n",
    "#         plt.scatter(x, y, s=3, edgecolors=\"gray\", facecolors='none', linewidth=0.2)\n",
    "\n",
    "#     else:\n",
    "#         plt.scatter(x, y, s=2)\n",
    "\n",
    "\n",
    "# ax.scatter(intermediary_nodes.lon, intermediary_nodes.lat, c='k', edgecolor='None', marker = \"x\", s=20, linewidth=1, zorder=3)\n",
    "# # ax.scatter(ports_clustered.lon, ports_clustered.lat, c=\"k\", s=20, marker=\"x\", linewidth=0.5)\n",
    "\n",
    "\n",
    "# plt.title(f\"Eps = {eps}, MinPts = {min_samples}\")\n",
    "\n",
    "\n",
    "# # ax.scatter(nodes_clustered.lon, nodes_clustered.lat, c='k', edgecolor='None', marker = \"x\", alpha=0.7, s=20, zorder=3)\n",
    "# # ax.scatter(df.lon, df.lat, c='k', edgecolor='None', marker = \"x\", alpha=0.7, s=0.1, zorder=3)\n",
    "# # ax.scatter(rdp_all_list[:, 1], rdp_all_list[:, 0], c='r', edgecolor='None', marker = \"x\", alpha=0.9, s=0.2, zorder=3)\n",
    "# # ax.scatter(ports_clustered.lon, ports_clustered.lat, c='limegreen', edgecolor='None', marker = \"x\", alpha=0.7, s=15, zorder=3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdp_all_list = np.concatenate(rdp_ships_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdp_all_list = np.concatenate(rdp_ships_list)\n",
    "import hdbscan\n",
    "\n",
    "# %matplotlib inline\n",
    "def HDBSCAN_(coords, min_cluster_size=10, min_points=2, labels=False, eps=False):\n",
    "    \"\"\"returns a dataframe of cluster coordinates and cluster ids formed by HDBSCAN\"\"\"\n",
    "    if eps:\n",
    "        eps = eps/6371\n",
    "        hdb = hdbscan.HDBSCAN(min_cluster_size, min_points, metric='haversine', cluster_selection_epsilon=eps, cluster_selection_method='eom').fit(np.radians(coords))\n",
    "\n",
    "    else:\n",
    "        hdb = hdbscan.HDBSCAN(min_cluster_size, min_points, metric='haversine').fit(np.radians(coords))\n",
    "\n",
    "    cluster_labels = hdb.labels_\n",
    "    num_clusters = len(set(cluster_labels))\n",
    "    clusters = pd.DataFrame([coords[cluster_labels == n] for n in range(num_clusters)], columns = ['value'])\n",
    "    clusters['Length'] = clusters.value.apply(lambda x: len(x))\n",
    "    clusters = clusters[clusters.Length > 0]\n",
    "    clusters = clusters['value']\n",
    "\n",
    "    centermost_points = clusters.map(get_centermost_point)\n",
    "    lats, lons = zip(*centermost_points)\n",
    "    rep_points = pd.DataFrame({'lat':lats, 'lon':lons})\n",
    "    \n",
    "    coords_clustered = np.apply_along_axis(lambda row: coords[(coords[:,0]==row[0]) & (coords[:,1]==row[1])][0], axis=1, arr=rep_points)\n",
    "    coords_clustered = pd.DataFrame(coords_clustered, columns=['lat', 'lon'])\n",
    "    coords_clustered = coords_clustered.reset_index(drop=True) \n",
    "    coords_clustered.index += 1 # start index from 1\n",
    "    coords_clustered['port_id'] = coords_clustered.index\n",
    "\n",
    "    cmap = plt.cm.get_cmap('turbo', num_clusters)\n",
    "\n",
    "    if labels:\n",
    "        return coords_clustered, cluster_labels\n",
    "\n",
    "    else:\n",
    "        return coords_clustered\n",
    "\n",
    "\n",
    "min_points = 30\n",
    "min_cluster_size = 30\n",
    "eps=25\n",
    "\n",
    "\n",
    "\n",
    "nodes_clustered, node_labels = HDBSCAN_(rdp_all_list, min_cluster_size=min_cluster_size, min_points=min_points, labels=True, eps=eps)\n",
    "nodes_clustered = nodes_clustered.rename(columns={'port_id': 'node_id'})\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(8,8), dpi=400)\n",
    "plt.figure(figsize=(5,5), dpi=400)\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "region = \"EU\"\n",
    "\n",
    "if region == \"CH\":\n",
    "    ax.set_extent([80, 160, -30, 50], crs=ccrs.PlateCarree())\n",
    "elif region ==\"EU\":\n",
    "    ax.set_extent([-12, 37, 30, 65], crs=ccrs.PlateCarree())\n",
    "elif region == \"US\":\n",
    "    ax.set_extent([-170, -45, 0, 70], crs=ccrs.PlateCarree())\n",
    "elif region == \"ME\":\n",
    "    ax.set_extent([20, 100, -45, 40], crs=ccrs.PlateCarree())\n",
    "elif region == \"AF\":\n",
    "    ax.set_extent([-20, 60, -45, 40], crs=ccrs.PlateCarree())\n",
    "\n",
    "\n",
    "\n",
    "# ax.coastlines()\n",
    "ax.add_feature(cfeature.LAND, facecolor=\"lightgrey\")\n",
    "gl = ax.gridlines(draw_labels=True, alpha=0.2, color=\"k\", linestyle='--', linewidth=0.3, xlocs=range(-180, 180, 10), ylocs=range(-90, 90, 10))\n",
    "# # ax.coastlines()\n",
    "gl.top_labels = False\n",
    "gl.right_labels = False\n",
    "gl.xlabel_style = {'size': 8, 'color': 'k'}\n",
    "gl.ylabel_style = {'size': 8, 'color': 'k'}\n",
    "gl.xpadding = 15 \n",
    "gl.ypadding = 10 \n",
    "for label in np.unique(node_labels):\n",
    "    mask = (node_labels == label)\n",
    "    x = rdp_all_list[:, 1][mask]\n",
    "    y = rdp_all_list[:, 0][mask]\n",
    "\n",
    "    if label == -1: # ignore -1 labels (noise)\n",
    "        plt.scatter(x, y, s=1, edgecolors=\"gray\", facecolors='none', linewidth=0.2)\n",
    "\n",
    "    else:\n",
    "        plt.scatter(x, y, s=1)\n",
    "# plt.legend()\n",
    "ax.scatter(nodes_clustered.lon, nodes_clustered.lat, c='k', edgecolor='None', marker = \"x\", s=10, linewidth=1, zorder=3)\n",
    "# ax.scatter(ports_clustered.lon, ports_clustered.lat, c=\"k\", s=20, marker=\"x\", linewidth=0.5)\n",
    "\n",
    "\n",
    "plt.title(f\"min_cluster_size = {min_cluster_size}, minPts = {min_points},  eps = {eps}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Database of Nodes (including ports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "max_port_id = ports_clustered.port_id.max()\n",
    "\n",
    "\n",
    "# ------------------- DATABASE OF ALL NODES (INCLUDING PORTS) -----------------\n",
    "def create_node_df():\n",
    "    add_port = lambda x: 'P' + str(x) # add a letter in front of each value\n",
    "    all_ports = ports_clustered[[\"lat\", \"lon\"]]\n",
    "    all_ports['id'] = ports_clustered['port_id'].apply(add_port)\n",
    "\n",
    "    add_node = lambda x: 'N' + str(x + max_port_id) # add a letter in front of each value\n",
    "\n",
    "    all_int_nodes = nodes_clustered[[\"lat\", \"lon\"]]\n",
    "    all_int_nodes['id'] = nodes_clustered['node_id'].apply(add_node)\n",
    "\n",
    "    all_nodes = pd.concat([all_ports, all_int_nodes])\n",
    "    all_nodes = all_nodes.reset_index(drop=True)\n",
    "\n",
    "    return all_nodes\n",
    "\n",
    "\n",
    "# IF VALUE of port is within 5km of value of node, delete node.\n",
    "\n",
    "def filter_nodes_within_distance(df, distance):\n",
    "    # split the dataframe into two dataframes, based on id prefix\n",
    "    df_n = df[df['id'].str.startswith('N')]\n",
    "    df_p = df[df['id'].str.startswith('P')]\n",
    "    \n",
    "    # distances between each node with 'N' and port with 'P'\n",
    "    distances = haversine_np(df_n['lon'].values[:, np.newaxis], df_n['lat'].values[:, np.newaxis],\n",
    "                             df_p['lon'].values[np.newaxis, :], df_p['lat'].values[np.newaxis, :])\n",
    "    \n",
    "    # minimum distance for each node N\n",
    "    min_distances = np.min(distances, axis=1)\n",
    "    \n",
    "    # remove nodes N within specified distance a port \n",
    "    filtered_nodes = df_n[min_distances > distance]\n",
    "    \n",
    "    # get the deleted nodes N and their closest ports\n",
    "    deleted_nodes = df_n[min_distances <= distance]\n",
    "    \n",
    "    df_p_reset = df_p.reset_index()\n",
    "    closest_ports = df_p_reset.loc[np.argmin(distances, axis=1), :][min_distances <= distance]\n",
    "    deleted_nodes['closest_port'] = closest_ports['id'].values    \n",
    "    result = pd.concat([filtered_nodes, df_p])\n",
    "    \n",
    "    return result, deleted_nodes\n",
    "\n",
    "all_nodes = create_node_df()\n",
    "all_nodes_f, deleted_nodes = filter_nodes_within_distance(all_nodes, 5)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nodes Visited for each record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Nodes visited\n",
    "\n",
    "df_rdp = pd.DataFrame.from_dict(ship_data_dict, orient='index')\n",
    "df_rdp = df_rdp.rename(columns={0: 'data'})  \n",
    "\n",
    "\n",
    "loop_val = 0\n",
    "temp_arr = []\n",
    "\n",
    "\n",
    "def remove_decimal(df, column_name):\n",
    "    \"\"\"\n",
    "    removes decimal point and following characters in a string\n",
    "    eg:\n",
    "    P12.0 becomes P12\n",
    "    \"\"\"\n",
    "\n",
    "    df[column_name] = np.where(~df[column_name].isna(),\n",
    "                               df[column_name].astype(str).str.replace(r'\\.\\d+', ''),\n",
    "                               df[column_name])\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_betw_node(df, node_column_name):\n",
    "    \"\"\"\n",
    "    This function calculates the 'from_node' and 'to_node' columns of a DataFrame based on a given 'node' column.\n",
    "    \"\"\"\n",
    "\n",
    "    df[\"node_value\"] = df[node_column_name].str[1:].astype(float) # extract node value\n",
    "    df[\"node_fwd\"] = df[\"node_value\"].ffill()\n",
    "    df[\"node_bwd\"] = df[\"node_value\"].bfill()\n",
    "    df[\"subtract1\"] = df[\"node_bwd\"] - df[\"node_value\"]\n",
    "    df[\"subtract1\"] = df[\"subtract1\"].replace(np.NaN, 1)\n",
    "    df[\"subtract1\"] = df[\"subtract1\"].replace(0, np.NaN)\n",
    "    df[\"from_node\"] = df[\"node_fwd\"] * df[\"subtract1\"]\n",
    "    df[\"to_node\"] = df[\"node_bwd\"] * df[\"subtract1\"]\n",
    "    \n",
    "    mask = df[\"from_node\"].notna()\n",
    "    df.loc[mask, \"from_node\"] = [\"N\"+str(node) if node > (max_port_id) else \"P\"+str(node) for node in df.loc[mask, \"from_node\"]]\n",
    "    df.loc[mask, \"to_node\"] = [\"N\"+str(node) if node > (max_port_id) else \"P\"+str(node) for node in df.loc[mask, \"to_node\"]]\n",
    "    \n",
    "    remove_decimal(df, 'from_node')\n",
    "    remove_decimal(df, 'to_node')\n",
    "    \n",
    "    df[\"betw_node\"] = list(zip(df[\"from_node\"], df[\"to_node\"]))\n",
    "    df.drop(columns=[\"subtract1\", \"node_fwd\", \"node_bwd\", \"from_node\", \"to_node\"], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "for imo, row in df_rdp.iterrows():\n",
    "\n",
    "    #---------------------- SET COLUMN WITH NODE VALUE ------------------------\n",
    "    node_values = node_labels[loop_val:(loop_val + len(row.data))]\n",
    "    node_values = np.where(node_values == -1, np.nan, node_values + 1 + max_port_id)    \n",
    "    node_values = ['N' + str(val) if not np.isnan(val) else np.nan for val in node_values] # add N in front of node number\n",
    "    node_values = [val.split('.')[0] if not pd.isna(val) else val for val in node_values]\n",
    "    \n",
    "    row_data = row.data.assign(node=node_values) # add node values as column \"node\"\n",
    "    loop_val += len(row.data)\n",
    "    \n",
    "    #--------------- IN PORT, SET PORT AS NODE IN NODE COLUMN ----------------\n",
    "    \n",
    "    # add port_id with \"P\" prefix to node column for non-nan port_id values\n",
    "    row_data[\"node\"] = np.where(row_data[\"port_id\"].isna(), row_data[\"node\"], \"P\" + row_data[\"port_id\"].astype(str))\n",
    "        \n",
    "    # remove decimal points from node column\n",
    "    row_data = remove_decimal(row_data, 'node')\n",
    "      \n",
    "    #------------------------ BETWEEN NODES COLUMN ----------------------------\n",
    "    row_data = create_betw_node(row_data, \"node\")   \n",
    "\n",
    "    #--------------------- REPLACE (nan, nan) with (node, node)----------------  \n",
    "\n",
    "    # replace nan values for node with tuple of node id it is at\n",
    "    row_data['betw_node'] = np.where(row_data['betw_node'].apply(lambda x: pd.isna(x[0]) and pd.isna(x[1])),  # condition\n",
    "                                    row_data['node'].apply(lambda x: (x, x)),  # new value\n",
    "                                    row_data['betw_node'])  # existing value\n",
    "    \n",
    "    #------------------CLOSEST POINT TO CENTROID WITHIN CLUSTER ---------------\n",
    "    new_data = pd.DataFrame()\n",
    "    row_data['betw_node_group'] = (row_data['betw_node'] != row_data['betw_node'].shift()).cumsum() # group same set of betw_port\n",
    "\n",
    "    for i, group in row_data.groupby(\"betw_node_group\"):\n",
    "        node_value = group.iloc[0][\"node\"]\n",
    "\n",
    "        if not pd.isna(node_value):\n",
    "        \n",
    "            if node_value.startswith(\"N\"): # closest point to centroid of node\n",
    "                # print(node_value)            \n",
    "                node_lat, node_lon = all_nodes.loc[all_nodes[\"id\"] == node_value, [\"lat\", \"lon\"]].values[0]\n",
    "                tree = BallTree(group[['lat', 'lon']].values, metric='haversine')\n",
    "                    \n",
    "                # find the index of the nearest neighbor for each point in the group\n",
    "                _, indices = tree.query([[node_lat, node_lon]], k=1)\n",
    "                \n",
    "                nearest_neighbor = group.iloc[indices[0]]                       \n",
    "                nearest_neighbor['at_node'] = nearest_neighbor['node'].copy() \n",
    "                group['at_node'] = nearest_neighbor['at_node']\n",
    "                group['at_node'] = group['at_node'].fillna(value=np.nan)\n",
    "                group.drop(columns=[\"betw_node\", \"betw_node_group\"], inplace=True)\n",
    "                \n",
    "            else: # if node is port node\n",
    "                group['at_node'] = group['node'].copy()\n",
    "                        \n",
    "        new_data = pd.concat([new_data, group], ignore_index=True)  \n",
    "        \n",
    "    new_data = create_betw_node(new_data, \"at_node\")  \n",
    "    \n",
    "    # replace nan values for port with tuple of port id it is in\n",
    "    new_data['betw_node'] = np.where(new_data['betw_node'].apply(lambda x: pd.isna(x[0]) and pd.isna(x[1])),  # condition\n",
    "                                    new_data['at_node'].apply(lambda x: (x, x)),  # new value\n",
    "                                    new_data['betw_node'])  # existing value\n",
    "    \n",
    "    # print(new_data)\n",
    "\n",
    "    result = new_data['betw_node'].apply(lambda x: x if (not str(x[0])[0].isalpha()) or (not str(x[1])[0].isalpha()) else None).dropna()\n",
    "    if not result.empty:\n",
    "        print(imo)\n",
    "        print(result)\n",
    "        print(new_data)\n",
    "\n",
    "    new_data['betw_node_group'] = (new_data['betw_node'] != new_data['betw_node'].shift()).cumsum() # group same set of betw_port \n",
    "\n",
    "    #------------------- OUTER COLUMN WITH ALL NODES VISITED ------------------\n",
    "    \n",
    "    nodes_visited_col = new_data['at_node'].tolist()\n",
    "    nodes_visited_nonan = [x for x in nodes_visited_col if not pd.isna(x)] # remove nan values first\n",
    "    nodes_visited_unique = [x[0] for x in groupby(nodes_visited_nonan)] # remove consecutive values that are the same\n",
    "    \n",
    "    #recalcualte distances and time differences after applying rdp\n",
    "    new_data = calc_distances(new_data)\n",
    "\n",
    "\n",
    "    record = {'IMO': imo, 'data': new_data, \"nodes_visited\": nodes_visited_unique}\n",
    "    temp_arr.append(record)     \n",
    "\n",
    "\n",
    "df_rdp_nodes = pd.DataFrame.from_records(temp_arr, index='IMO')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ship_network(df):\n",
    "    result_dict = {}\n",
    "    for imo, row in df.iterrows():\n",
    "        display(row.data[['IMO', 'lat', 'lon', 'sog', 'datetime', 'dist', 'time_diff', 'port_id', 'betw_port', 'node', 'betw_node']])\n",
    "        break\n",
    "\n",
    "create_ship_network(df_rdp_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rdp_nodes = pd.read_pickle(\"df_rdp_nodes.pkl\")\n",
    "def create_ship_network(df):\n",
    "    result_dict = {}\n",
    "    for imo, row in df.iterrows():\n",
    "        data_frames = []\n",
    "        prev_node_comb = 0\n",
    "        for i, port_group in row.data.groupby(\"betw_port_group\"):\n",
    "\n",
    "            port_comb = port_group.iloc[0][\"betw_port\"] \n",
    "            print(\"=============================================================================\")\n",
    "            print(\"---------------------NEW PORT COMB-\", port_comb, \"--------------------\")\n",
    "            print(\"port_group\", port_group)\n",
    "            print(\"-----------------------------------------------------------------------------\")\n",
    "\n",
    "            data_df = pd.DataFrame()\n",
    "            data_df[\"betw_port\"] = [port_comb]\n",
    "            node_data_df = pd.DataFrame(columns=[\"betw_node\", \"time_diff\", \"dist\", \"start_month\"]) \n",
    "\n",
    "            first_iter = True\n",
    "            for j, node_group in port_group.groupby(\"betw_node_group\"):\n",
    "                node_comb = node_group.iloc[0][\"betw_node\"] \n",
    "                # print(node_comb)\n",
    "                at_node_value = node_group.iloc[0][\"at_node\"] \n",
    "\n",
    "                next_group = port_group[port_group[\"betw_node_group\"] == j+1]\n",
    "                prev_group = port_group[port_group[\"betw_node_group\"] == j-1]\n",
    "\n",
    "                # print(\"Previous = \", prev_group)\n",
    "                start_month = node_group.iloc[0][\"datetime\"].month\n",
    "                \n",
    "                if node_comb[0] == node_comb[1] and node_comb[1].startswith(\"P\"):\n",
    "                    total_time = port_group.iloc[-1][\"datetime\"] - port_group.iloc[0][\"datetime\"]\n",
    "                    # total_dist = port_group[\"dist\"].sum()\n",
    "                    total_dist = 0 #(in port)\n",
    "                    \n",
    "                    node_data_row = {'betw_node': node_comb, \"time_diff\": total_time, \"dist\": total_dist, \"start_month\": start_month} # Define a dictionary with the values for each column\n",
    "                    node_data_df = node_data_df.append(node_data_row, ignore_index=True)\n",
    "\n",
    "                    # print(\"Added -a): \", node_comb)\n",
    "                    last_added = node_comb\n",
    "                    break\n",
    "\n",
    "                else: \n",
    "                    if prev_group.empty and next_group.empty: # eg ('P29', 'P101') when at P101 (going only between two ports)\n",
    "                        #add port\n",
    "\n",
    "                        total_time = row.data[row.data[\"betw_port_group\"] == i + 1].iloc[0][\"datetime\"] - row.data[row.data[\"betw_port_group\"] == i - 1].iloc[0][\"datetime\"]\n",
    "                        total_dist = node_group[\"dist\"].sum() + row.data[row.data[\"betw_port_group\"] == i + 1].iloc[0][\"dist\"]\n",
    "                        node_data_row = {'betw_node': node_comb, \"time_diff\": total_time, \"dist\": total_dist, \"start_month\": start_month} # Define a dictionary with the values for each column\n",
    "                        node_data_df = node_data_df.append(node_data_row, ignore_index=True)\n",
    "                        # print(\"Added a): \", node_comb)\n",
    "                        last_added = node_comb\n",
    "                    \n",
    "                    elif prev_group.empty and not next_group.empty:\n",
    "                        \n",
    "\n",
    "                        if pd.isna(at_node_value):\n",
    "                            total_time = node_group.iloc[0][\"time_diff\"] \n",
    "                            total_dist = node_group.iloc[0][\"dist\"] \n",
    "                            node_data_row = {'betw_node': node_comb, \"time_diff\": total_time, \"dist\": total_dist, \"start_month\": start_month} # Define a dictionary with the values for each column\n",
    "                            node_data_df = node_data_df.append(node_data_row, ignore_index=True)\n",
    "\n",
    "                            # print(\"Added b)\", node_comb) # between node value\n",
    "                            last_added = node_comb\n",
    "\n",
    "                        else:\n",
    "                            \n",
    "                            new_node_comb = (\"P\" + str(int(port_comb[0])), at_node_value)\n",
    "                            total_time = node_group.iloc[0][\"time_diff\"] \n",
    "                            total_dist = node_group.iloc[0][\"dist\"] \n",
    "                            node_data_row = {'betw_node': new_node_comb, \"time_diff\": total_time, \"dist\": total_dist, \"start_month\": start_month} # Define a dictionary with the values for each column\n",
    "                            node_data_df = node_data_df.append(node_data_row, ignore_index=True)\n",
    "\n",
    "                            # print(\"Added c)\" , new_node_comb)\n",
    "                            # if it is a node=node, time spent at node is zero, distance is zero as well\n",
    "                            total_time = datetime.timedelta()  # last \n",
    "                            total_dist = 0 # last\n",
    "                            node_data_row = {'betw_node': node_comb, \"time_diff\": total_time, \"dist\": total_dist, \"start_month\": start_month} # Define a dictionary with the values for each column\n",
    "                            node_data_df = node_data_df.append(node_data_row, ignore_index=True)\n",
    "                            # print(\"Added c)\" , node_comb)\n",
    "                            \n",
    "                            last_added = node_comb\n",
    "                    \n",
    "                    \n",
    "                    elif not prev_group.empty and not next_group.empty:\n",
    "                        if last_added[1] == at_node_value: \n",
    "\n",
    "                            total_time = datetime.timedelta()\n",
    "                            total_dist = 0\n",
    "                            \n",
    "                            node_data_row = {'betw_node': node_comb, \"time_diff\": total_time, \"dist\": total_dist, \"start_month\": start_month} # Define a dictionary with the values for each column\n",
    "                            node_data_df = node_data_df.append(node_data_row, ignore_index=True)\n",
    "\n",
    "                            # print(\"Added d)\" , node_comb)\n",
    "                            last_added = node_comb\n",
    "\n",
    "                        elif not pd.isna(at_node_value):\n",
    "                            new_node_comb = (last_added[1], at_node_value)\n",
    "                            total_time = node_group.iloc[0][\"time_diff\"] \n",
    "                            total_dist = node_group.iloc[0][\"dist\"] \n",
    "                            node_data_row = {'betw_node': new_node_comb, \"time_diff\": total_time, \"dist\": total_dist, \"start_month\": start_month} # Define a dictionary with the values for each column\n",
    "                            node_data_df = node_data_df.append(node_data_row, ignore_index=True)\n",
    "\n",
    "                            # print(\"Added e)\", new_node_comb)\n",
    "                            \n",
    "                            total_time = datetime.timedelta()\n",
    "                            total_dist = 0\n",
    "\n",
    "                            node_data_row = {'betw_node': node_comb, \"time_diff\": total_time, \"dist\": total_dist, \"start_month\": start_month} # Define a dictionary with the values for each column\n",
    "                            node_data_df = node_data_df.append(node_data_row, ignore_index=True)\n",
    "                            # print(\"Added e)\", node_comb)\n",
    "                            last_added = node_comb\n",
    "\n",
    "                        else: # nan value \n",
    "                            total_time = next_group.iloc[0][\"datetime\"] - prev_group.iloc[-1][\"datetime\"]\n",
    "                            total_dist = node_group.dist.sum() + next_group.iloc[0][\"dist\"]  \n",
    "\n",
    "                            node_data_row = {'betw_node': node_comb, \"time_diff\": total_time, \"dist\": total_dist, \"start_month\": start_month} # Define a dictionary with the values for each column\n",
    "                            node_data_df = node_data_df.append(node_data_row, ignore_index=True)\n",
    "                        \n",
    "                            # print(\"Added f) \", node_comb)\n",
    "                            last_added = node_comb\n",
    "\n",
    "                    elif not prev_group.empty and next_group.empty:\n",
    "                        if last_added[1] == at_node_value: \n",
    "\n",
    "                            total_time = datetime.timedelta()\n",
    "                            total_dist = 0\n",
    "\n",
    "                            node_data_row = {'betw_node': node_comb, \"time_diff\": total_time, \"dist\": total_dist, \"start_month\": start_month} # Define a dictionary with the values for each column\n",
    "                            node_data_df = node_data_df.append(node_data_row, ignore_index=True)\n",
    "\n",
    "                            # print(\"Added g)\" , node_comb)\n",
    "\n",
    "                            if node_comb[1].startswith(\"N\"):\n",
    "                                new_node_comb = (at_node_value, \"P\" + str(int(port_comb[1])))\n",
    "                                total_time = row.data[row.data[\"betw_port_group\"] == i + 1].iloc[0][\"time_diff\"] # NEXT GROUP VALUE\n",
    "                                total_dist = row.data[row.data[\"betw_port_group\"] == i + 1].iloc[0][\"dist\"] \n",
    "                                node_data_row = {'betw_node': new_node_comb, \"time_diff\": total_time, \"dist\": total_dist, \"start_month\": start_month} # Define a dictionary with the values for each column\n",
    "                                node_data_df = node_data_df.append(node_data_row, ignore_index=True)\n",
    "\n",
    "                                # print(\"Added g)\" , new_node_comb)\n",
    "                                last_added = node_comb\n",
    "\n",
    "                            last_added = node_comb\n",
    "\n",
    "                        elif not pd.isna(at_node_value):\n",
    "                            new_node_comb = (last_added[1], at_node_value)\n",
    "                            total_time = node_group.iloc[0][\"time_diff\"] \n",
    "                            total_dist = node_group.iloc[0][\"dist\"] \n",
    "                            node_data_row = {'betw_node': new_node_comb, \"time_diff\": total_time, \"dist\": total_dist, \"start_month\": start_month} # Define a dictionary with the values for each column\n",
    "                            node_data_df = node_data_df.append(node_data_row, ignore_index=True)\n",
    "\n",
    "                            # print(\"Added h)\", new_node_comb)\n",
    "\n",
    "                            total_time = datetime.timedelta()\n",
    "                            total_dist = 0\n",
    "                            node_data_row = {'betw_node': node_comb, \"time_diff\": total_time, \"dist\": total_dist, \"start_month\": start_month} # Define a dictionary with the values for each column\n",
    "                            node_data_df = node_data_df.append(node_data_row, ignore_index=True)\n",
    "\n",
    "                            # print(\"Added h)\" , node_comb)\n",
    "\n",
    "                            if node_comb[1].startswith(\"N\"):\n",
    "                                new_node_comb = (at_node_value, \"P\" + str(int(port_comb[1])))\n",
    "                                total_time = row.data[row.data[\"betw_port_group\"] == i + 1].iloc[0][\"time_diff\"] # NEXT GROUP VALUE\n",
    "                                total_dist = row.data[row.data[\"betw_port_group\"] == i + 1].iloc[0][\"dist\"] \n",
    "                                node_data_row = {'betw_node': new_node_comb, \"time_diff\": total_time, \"dist\": total_dist, \"start_month\": start_month} # Define a dictionary with the values for each column\n",
    "                                node_data_df = node_data_df.append(node_data_row, ignore_index=True)\n",
    "\n",
    "                                # print(\"Added h)\" , new_node_comb)\n",
    "                            last_added = node_comb\n",
    "\n",
    "                        else: # N601 -> NaN -> P4 (last value is nan)\n",
    "                            total_time = row.data[row.data[\"betw_port_group\"] == i + 1].iloc[0][\"datetime\"] - prev_group.iloc[-1][\"datetime\"] \n",
    "                            total_dist = port_group[\"dist\"].sum() + row.data[row.data[\"betw_port_group\"] == i + 1].iloc[0][\"dist\"]\n",
    "                            node_data_row = {'betw_node': node_comb, \"time_diff\": total_time, \"dist\": total_dist, \"start_month\": start_month} # Define a dictionary with the values for each column\n",
    "                            node_data_df = node_data_df.append(node_data_row, ignore_index=True)\n",
    "\n",
    "                            # print(\"Added i) \", node_comb)\n",
    "                            last_added = node_comb\n",
    "                \n",
    "                # else: \n",
    "                #     print(\"!!!!!!!!!MISSING!!!!!!!!!!\", node_comb)\n",
    "\n",
    "            data_df[\"node_data\"] = [node_data_df]\n",
    "            data_frames.append(data_df)\n",
    "        result_dict[imo] = pd.concat(data_frames, ignore_index=True)\n",
    "    return pd.DataFrame([result_dict])\n",
    "\n",
    "\n",
    "df_ship_network_test = create_ship_network(df_rdp_nodes)\n",
    "df_ship_network_T = df_ship_network_test.T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Ports Visited per Ship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for imo, row in df_ship_network_T.iterrows():\n",
    "    betw_port_level = row.T[0]\n",
    "    ports_only = betw_port_level[betw_port_level[\"betw_port\"].apply(lambda x: x[0] == x[1])]\n",
    "    # display(ports_only)\n",
    "    total = len(ports_only)\n",
    "    # display(ports_only[\"betw_port\"].unique())\n",
    "    num_unique_betw_ports = ports_only[\"betw_port\"].nunique()\n",
    "    # print(\"Ship:\", imo, \"unique ports:\", num_unique_betw_ports, \"total:  \", total)\n",
    "    df_ship_network_T.at[imo, \"total_ports\"] = total\n",
    "    df_ship_network_T.at[imo, \"unique_ports\"] = num_unique_betw_ports\n",
    "    df_ship_network_T.at[imo, \"repeatability\"] = total - num_unique_betw_ports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_nonzero = (len(df_ship_network_T[df_ship_network_T['repeatability'] == 0]) / len(df_ship_network_T)) * 100\n",
    "print(percentage_nonzero)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHIP DETAILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ship_details = pd.read_csv(folder_loc + r\"\\bulk_carrier_data\\ship_details.csv\")\n",
    "ship_details_all = pd.read_csv(folder_loc + r\"\\bulk_carrier_data\\ship_details_all.csv\")\n",
    "\n",
    "ship_details[\"IMO Number\"] = ship_details[\"IMO Number\"].astype(str)\n",
    "ship_details_all[\"IMO Number\"] = ship_details_all[\"IMO Number\"].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ship_network_T['IMO'] = df_ship_network_T.index\n",
    "df_ship_network_T['IMO'] = df_ship_network_T['IMO'].astype(str)\n",
    "\n",
    "# extract the IMO number from the \"IMO\" column\n",
    "df_ship_network_T[\"IMO_number\"] = df_ship_network_T[\"IMO\"].str.split(\"_\").str[0]\n",
    "\n",
    "# create a dictionary mapping IMO numbers to capacities from the other dataframe\n",
    "imo_capacity_dict = dict(zip(ship_details_all[\"IMO Number\"].str.split(\"_\").str[0], ship_details_all[\"Deadweight\"]))\n",
    "\n",
    "# map the IMO number to the corresponding capacity value\n",
    "df_ship_network_T[\"Deadweight\"] = df_ship_network_T[\"IMO_number\"].map(imo_capacity_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ships that arent in amys data\n",
    "a1 = df_ship_network_T[\"IMO_number\"]\n",
    "a2 = ship_details[\"IMO Number\"]\n",
    "df_ship_network_T[\"IMO_number\"] = df_ship_network_T[\"IMO\"].str.split(\"_\").str[0]\n",
    "not_in_ship_details = ~df_ship_network_T[\"IMO_number\"].isin(ship_details[\"IMO Number\"])\n",
    "df_ship_network_T_not_in_ship_details = df_ship_network_T[not_in_ship_details]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ship_network_T_not_in_ship_details = df_ship_network_T_not_in_ship_details.sort_values(by=\"Deadweight\")\n",
    "\n",
    "imo_number = df_ship_network_T_not_in_ship_details[\"IMO_number\"]\n",
    "total_ports = df_ship_network_T_not_in_ship_details[\"total_ports\"]\n",
    "unique_ports = df_ship_network_T_not_in_ship_details[\"unique_ports\"]\n",
    "dwt = df_ship_network_T_not_in_ship_details[\"Deadweight\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,3), dpi=200)\n",
    "ax.bar(imo_number, total_ports, label=\"Total Destinations\", color=\"k\")\n",
    "ax.bar(imo_number, unique_ports, label=\"Unique Destinations\", color=\"steelblue\")\n",
    "ax.set_xlabel(\"Ship (increasing deadweight)\")\n",
    "ax.set_ylabel(\"Number of Destinations\")\n",
    "ax.legend()\n",
    "ax.set_xticklabels(\"\")\n",
    "ax.set_xticks(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reverse Geocoding (Mapbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from geopy.distance import distance\n",
    "from sklearn.neighbors import BallTree\n",
    "import pycountry\n",
    "\n",
    "country_code_dict = {}\n",
    "for country in pycountry.countries:\n",
    "    country_code_dict[country.alpha_2] = country.name\n",
    "\n",
    "wpi_ports = gpd.read_file(r'C:\\Users\\Nefelie\\OneDrive - University of Southampton\\Uni\\3rd Year\\Individual Project\\other\\World_Port_Index\\World_Port_Index.shp')\n",
    "tree = BallTree(np.radians(wpi_ports[['LATITUDE', 'LONGITUDE']].values), leaf_size=15, metric='haversine')\n",
    "\n",
    "access_token = 'INSERT OWN API ACCESS TOKEN'\n",
    "geocoding_endpoint = 'mapbox.places'\n",
    "\n",
    "def geopy_distance(coords1, coords2):\n",
    "    return distance(coords2, coords1)\n",
    "\n",
    "for index, row in all_nodes.iterrows():\n",
    "    lat, lon = row['lat'], row['lon']\n",
    "    url = f\"https://api.mapbox.com/geocoding/v5/{geocoding_endpoint}/{lon},{lat}.json?access_token={access_token}&types=country\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    features = data.get('features', [])\n",
    "    if len(features) > 0:\n",
    "        country = features[0]['text']\n",
    "        if country == 'Russian Federation':\n",
    "            country = 'Russia'\n",
    "\n",
    "    else:\n",
    "        # country = None\n",
    "\n",
    "        dist, ind = tree.query([np.radians([lat, lon])], k=1)\n",
    "        closest_node = wpi_ports.iloc[ind[0][0]]\n",
    "        closest_distance = distance((lat, lon), (closest_node['LATITUDE'], closest_node['LONGITUDE'])).km\n",
    "        # print(closest_distance)\n",
    "        if closest_distance <= 2000:\n",
    "            country = closest_node['COUNTRY']\n",
    "            # print(country)\n",
    "            country = pycountry.countries.get(alpha_2=country).name\n",
    "            # print(country)\n",
    "            if country == 'Russian Federation':\n",
    "                country = 'Russia'\n",
    "\n",
    "\n",
    "        else:\n",
    "            print(row[\"id\"], closest_distance)\n",
    "            country = None\n",
    "\n",
    "    all_nodes.at[index, 'country'] = country\n",
    "\n",
    "p_rows = all_nodes[all_nodes['id'].str.startswith('P')]  # Filter rows where ID starts with 'P'\n",
    "p_nan_count = p_rows['country'].isna().sum()  # Count the number of NaN values in the column\n",
    "p_percent_nan = p_nan_count / len(p_rows) * 100  # Calculate the percentage of NaN values\n",
    "print(p_percent_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_nodes = all_nodes[all_nodes['id'].str.startswith('P')]\n",
    "\n",
    "num_countries = len(p_nodes['country'].unique())\n",
    "\n",
    "print(f\"Number of countries in p_nodes starting with 'P': {num_countries}\")\n",
    "top_port_countries = pd.DataFrame({'country': p_nodes['country'].value_counts().head(10).index, 'no_ports': p_nodes['country'].value_counts().head(10).values})\n",
    "top_port_countries = top_port_countries.reset_index(drop=True)\n",
    "top_port_countries.index = top_port_countries.index + 1\n",
    "display(top_port_countries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p_nan_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crs_plot(world_bw=False, world_color=False, t=True, b=True, l=True, r=True, x_spac=45, y_spac=45):\n",
    "    \"\"\"Generate a plot in the PlateCarree projection\"\"\"\n",
    "    plt.figure(dpi=400)\n",
    "    ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=0))\n",
    "    gl = ax.gridlines(draw_labels=True, alpha=0.2, color=\"k\", linestyle='--', linewidth=0.3, xlocs=range(-180, 180, x_spac), ylocs=range(-90, 90, y_spac))\n",
    "    gl.top_labels = t\n",
    "    gl.right_labels = r\n",
    "    gl.bottom_labels = b\n",
    "    gl.left_labels = l\n",
    "    gl.xlabel_style = {'size': 8, 'color': 'k'}\n",
    "    gl.ylabel_style = {'size': 8, 'color': 'k'}\n",
    "    gl.xpadding = 15 \n",
    "    gl.ypadding = 10 \n",
    "\n",
    "    if world_color:\n",
    "        ax.add_feature(cfeature.LAND)\n",
    "        ax.add_feature(cfeature.OCEAN)\n",
    "        ax.add_feature(cfeature.BORDERS, linestyle='-', alpha=.5, linewidth=0.1)\n",
    "    \n",
    "    elif world_bw:\n",
    "        ax.add_feature(cfeature.LAND, color=\"lightgrey\")\n",
    "\n",
    "    return plt, ax\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ships MultiGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_ships_multi = nx.MultiGraph()\n",
    "\n",
    "for imo, row in df_ship_network_T.iterrows():\n",
    "    row_data = row.T.iloc[0]\n",
    "    for _, sub_row in row_data.iterrows():\n",
    "        port_comb = sub_row[0]\n",
    "        for _, node_group in sub_row[-1].iterrows():\n",
    "            node_comb = node_group['betw_node']\n",
    "            G_ships_multi.add_edge(node_comb[0], node_comb[1],\n",
    "                                   time=node_group.loc['time_diff'], \n",
    "                                   dist=node_group.loc['dist'], \n",
    "                                   start_month=node_group.loc['start_month'],\n",
    "                                   ship_imo=imo, \n",
    "                                   port_comb=port_comb)\n",
    "\n",
    "for u, v, edge_attrs in G_ships_multi.edges(data=True):\n",
    "    if u == v:  # Check if self-loop edge\n",
    "        if u.startswith(\"P\"):\n",
    "            node_type=\"P\"\n",
    "        else:\n",
    "            node_type=\"N\"\n",
    "        lat = all_nodes.loc[all_nodes['id'] == u, 'lat'].iloc[0]\n",
    "        lon = all_nodes.loc[all_nodes['id'] == u, 'lon'].iloc[0]\n",
    "        country = all_nodes.loc[all_nodes['id'] == u, 'country'].iloc[0]\n",
    "        G_ships_multi.add_node(u, lat=lat, lon=lon, country=country, start_month=edge_attrs[\"start_month\"], ship_imo=edge_attrs[\"ship_imo\"], time=edge_attrs[\"time\"], node_type=node_type)\n",
    "\n",
    "# for i, row in all_nodes.iterrows():\n",
    "#     if row.id.startswith(\"N\"):\n",
    "#         node_type = \"N\"\n",
    "#     elif row.id.startswith(\"P\"):\n",
    "#         node_type = \"P\"\n",
    "#     G_ships_multi.add_node(row.id, lat=row['lat'], lon=row['lon'], node_type=node_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_G_ships_multi = nx.to_pandas_edgelist(G_ships_multi)\n",
    "display(df_G_ships_multi[105:115])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_ships_multi.remove_edges_from(nx.selfloop_edges(G_ships_multi))\n",
    "pos = {node: (G_ships_multi.nodes[node]['lon'], G_ships_multi.nodes[node]['lat']) for node in G_ships_multi.nodes}\n",
    "plt, ax = crs_plot(world_bw=True, world_color=True)\n",
    "plt.scatter(df.lon, df.lat, s=0.05, linewidth=0.01, alpha=0.5, c=\"lavender\", zorder=1)\n",
    "nx.draw_networkx_nodes(G_ships_multi, pos, node_size=0.1, node_color='k', ax=ax)\n",
    "nx.draw_networkx_edges(G_ships_multi, pos, edge_color='k', alpha=0.5, width=0.05, ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of Anchored Ship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_ships.loc[\"9498896\"][\"data\"][\"lon\"])\n",
    "plt.scatter(df_ships.loc[\"9498896\"][\"data\"][\"lon\"], df_ships.loc[\"9498896\"][\"data\"][\"lat\"], s=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imo_test = \"9498896\"\n",
    "\n",
    "ship_edges = [(u, v, data) for u, v, data in G_ships_multi.edges(data=True) if data['ship_imo']==imo_test]\n",
    "print(ship_edges)\n",
    "\n",
    "pos_ships = {node:(data['lon'], data['lat']) for node, data in G_ships_multi.nodes(data=True)}\n",
    "\n",
    "plt, ax = crs_plot(world_bw=True, world_color=False, x_spac=1, y_spac=1)\n",
    "\n",
    "plt.scatter(df_ships.loc[\"9498896\"][\"data\"][\"lon\"], df_ships.loc[\"9498896\"][\"data\"][\"lat\"], s=0.01, label=\"ship track\")\n",
    "nx.draw_networkx_edges(G_ships_multi, pos_ships, edgelist=ship_edges, edge_color='r', width=1.0, alpha=0.7, label=\"edges\")\n",
    "\n",
    "ax.set_extent([-16, -14, 10, 12], crs=ccrs.PlateCarree())\n",
    "plt.legend(markerscale=10)\n",
    "plt.title(f\"IMO {imo_test}\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ports graph"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MultiGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_ports_multi = nx.MultiGraph()\n",
    "\n",
    "for imo, row in df_ship_network_T.iterrows():\n",
    "    row_data = row.T.iloc[0]\n",
    "    port_comb_dict = {}\n",
    "    for _, sub_row in row_data.iterrows():\n",
    "        port_comb = sub_row[0]\n",
    "        port_comb = tuple([\"P\" + str(int(val)) for val in port_comb])\n",
    "        # If this port_combination hasn't been seen before, add it to the dictionary\n",
    "        if port_comb not in port_comb_dict:\n",
    "            port_comb_dict[port_comb] = {'time': datetime.timedelta(0), 'dist': 0, 'imo': set()}\n",
    "\n",
    "        for _, node_group in sub_row[-1].iterrows():\n",
    "            node_comb = node_group['betw_node']\n",
    "            port_comb_dict[port_comb]['time'] += pd.Timedelta(node_group['time_diff'])\n",
    "            port_comb_dict[port_comb]['dist'] += pd.Series(node_group['dist']).sum()\n",
    "            port_comb_dict[port_comb]['imo'].update({imo})\n",
    "\n",
    "    for port_comb, edge_attrs in port_comb_dict.items():\n",
    "        G_ports_multi.add_edge(port_comb[0], port_comb[1], time=edge_attrs['time'], dist=edge_attrs['dist'], imo=list(edge_attrs['imo']))\n",
    "\n",
    "\n",
    "# Add self-loop edges as nodes to the graph with the same attributes as the edges\n",
    "for u, v, edge_attrs in G_ports_multi.edges(data=True):\n",
    "    if u == v and u.startswith(\"P\"):  # Check if it's a self-loop edge\n",
    "        lat = all_nodes.loc[all_nodes['id'] == u, 'lat'].iloc[0]\n",
    "        lon = all_nodes.loc[all_nodes['id'] == u, 'lon'].iloc[0]\n",
    "        country = all_nodes.loc[all_nodes['id'] == u, 'country'].iloc[0]\n",
    "        G_ports_multi.add_node(u, lat=lat, lon=lon, country=country)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G_ports_multi.remove_edges_from(nx.selfloop_edges(G_ports_multi))\n",
    "pos = {node: (G_ports_multi.nodes[node]['lon'], G_ports_multi.nodes[node]['lat']) for node in G_ports_multi.nodes}\n",
    "plt, ax = crs_plot(world_bw=True, world_color=False)\n",
    "nx.draw_networkx_nodes(G_ports_multi, pos, node_size=1, node_color='k', ax=ax)\n",
    "nx.draw_networkx_edges(G_ports_multi, pos, edge_color='k', alpha=0.1, width=0.5, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DiGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_ships_ports = nx.Graph() #NOTE SHOULD BE DIRECTED GRAPH\n",
    "for u, v in G_ports_multi.edges():\n",
    "    edge_dict = G_ports_multi[u][v]\n",
    "    no_trips = len(edge_dict)\n",
    "    dists = [edge_dict[i]['dist'] for i in range(no_trips)]\n",
    "    time_diffs = [edge_dict[i]['time'].total_seconds() for i in range(no_trips)]\n",
    "\n",
    "    if len(dists) > 0:\n",
    "        mean_dist, std_dist = np.mean(dists), np.std(dists)\n",
    "    else:\n",
    "        mean_dist, std_dist = np.nan, np.nan\n",
    "\n",
    "    if len(time_diffs) > 0:\n",
    "        mean_time, std_time = datetime.timedelta(seconds=np.mean(time_diffs)), datetime.timedelta(seconds=np.std(time_diffs))\n",
    "    else:\n",
    "        mean_time, std_time = np.nan, np.nan\n",
    "\n",
    "    if not G_ships_ports.has_edge(u, v):\n",
    "        G_ships_ports.add_edge(u, v, no_trips=no_trips, mean_dist=mean_dist, std_dist=std_dist, mean_time=mean_time, std_time=std_time)\n",
    "    else:\n",
    "        G_ships_ports[u][v]['no_trips'] = no_trips\n",
    "        G_ships_ports[u][v]['mean_dist'] = mean_dist\n",
    "        G_ships_ports[u][v]['std_dist'] = std_dist\n",
    "        G_ships_ports[u][v]['mean_time'] = mean_time\n",
    "        G_ships_ports[u][v]['std_time'] = std_time\n",
    "\n",
    "# for i, row in all_nodes.iterrows():\n",
    "#     if row.id.startswith(\"N\"):\n",
    "#         node_type = \"N\"\n",
    "#     elif row.id.startswith(\"P\"):\n",
    "#         node_type = \"P\"\n",
    "#     G_ships_ports.add_node(row.id, lat=row['lat'], lon=row['lon'], node_type=node_type)\n",
    "\n",
    "# Add self-loop edges as nodes to the graph with the same attributes as the edges\n",
    "for u, v, edge_attrs in G_ships_ports.edges(data=True):\n",
    "    if u == v and u.startswith(\"P\"):  # Check if it's a self-loop edge\n",
    "        lat = all_nodes.loc[all_nodes['id'] == u, 'lat'].iloc[0]\n",
    "        lon = all_nodes.loc[all_nodes['id'] == u, 'lon'].iloc[0]\n",
    "        country = all_nodes.loc[all_nodes['id'] == u, 'country'].iloc[0]\n",
    "        mean_time = G_ships_ports[u][v]['mean_time']\n",
    "        std_time = G_ships_ports[u][v]['std_time']\n",
    "        G_ships_ports.add_node(u, lat=lat, lon=lon, country=country, mean_time=mean_time, std_time=std_time)\n",
    "\n",
    "\n",
    "G_ships_ports.remove_edges_from(nx.selfloop_edges(G_ships_ports))\n",
    "df_G_ships_ports = nx.to_pandas_edgelist(G_ships_ports)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = {node_id: (lon, lat) for node_id, lat, lon in zip(all_nodes['id'], all_nodes['lat'], all_nodes['lon'])}\n",
    "\n",
    "plt, ax = crs_plot(world_bw=True)\n",
    "nx.draw_networkx_edges(G_ships_ports, pos, width=0.1)\n",
    "nx.draw_networkx_nodes(G_ships_ports, pos, node_size=1, node_color=\"r\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean time spent in port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_times = {u: G_ships_ports.nodes[u]['mean_time'] for u in G_ships_ports.nodes() if u.startswith(\"P\")}\n",
    "mean_times_float = np.array([mean_time.total_seconds() for node, mean_time in mean_times.items()])\n",
    "sizes = 200 * (mean_times_float - mean_times_float.min()) / (mean_times_float.max() - mean_times_float.min())\n",
    "\n",
    "plt, ax = crs_plot(world_bw=True)\n",
    "\n",
    "pos = {node: (G_ships_ports.nodes[node]['lon'], G_ships_ports.nodes[node]['lat']) for node in G_ships_ports.nodes()}\n",
    "nx.draw_networkx_nodes(G_ships_ports, pos, nodelist=[node for node in G_ships_ports.nodes() if node.startswith(\"P\")],\n",
    "                       node_size=sizes, alpha=0.5, node_color='blue')\n",
    "nx.draw_networkx_edges(G_ships_ports, pos, alpha=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cmasher as cmr\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "mean_times = nx.get_node_attributes(G_ships_ports, 'mean_time')\n",
    "std_times = nx.get_node_attributes(G_ships_ports, 'std_time')\n",
    "\n",
    "std_times = [std_times[node].total_seconds() / (24*60*60) for node in G_ships_ports.nodes() if node.startswith(\"P\")]  # convert to days\n",
    "mean_times = [mean_times[node].total_seconds() / (24*60*60) for node in G_ships_ports.nodes() if node.startswith(\"P\")]  # convert to days\n",
    "sorted_nodes = sorted([(node, std_times[i]) for i, node in enumerate(G_ships_ports.nodes()) if node.startswith(\"P\")], key=lambda x: x[1])\n",
    "sorted_nodes = [node for node, _ in sorted_nodes]\n",
    "\n",
    "pos = {node: (G_ships_ports.nodes[node]['lon'], G_ships_ports.nodes[node]['lat']) for node in G_ships_ports.nodes()}\n",
    "\n",
    "sizes = [std_times[i]*0.5 for i in range(len(G_ships_ports.nodes())) if list(G_ships_ports.nodes())[i].startswith(\"P\")]\n",
    "node_colors = [mean_times[i] for i in range(len(G_ships_ports.nodes())) if list(G_ships_ports.nodes())[i].startswith(\"P\")]\n",
    "vmax = 30\n",
    "\n",
    "\n",
    "cmap = cmr.get_sub_cmap('gnuplot2', 0, 0.95)\n",
    "vmin = min(node_colors)\n",
    "cmap_values = plt.Normalize(vmin=vmin, vmax=vmax)(node_colors)\n",
    "cmap_colors = cmap(cmap_values)\n",
    "white_nodes = ['white' if node_colors[i]>vmax else cmap_colors[i] for i in range(len(node_colors))]\n",
    "\n",
    "plt, ax = crs_plot(world_bw=True, world_color=True)\n",
    "\n",
    "nx.draw_networkx_nodes(G_ships_ports, pos, nodelist=sorted_nodes,\n",
    "                       node_size=sizes, alpha=1, node_color=white_nodes)\n",
    "\n",
    "# nx.draw_networkx_edges(G_ships_ports, pos, alpha=0.1)\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "sm.set_array([])\n",
    "cbar = plt.colorbar(sm, orientation='horizontal', pad=0.1, aspect=50)\n",
    "cbar.ax.tick_params(labelsize=8)\n",
    "cbar.minorticks_on()\n",
    "cbar.set_label('Mean Ship Waiting and Berthing Time (days)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "%matplotlib inline\n",
    "\n",
    "mean_times = nx.get_node_attributes(G_ships_ports, 'mean_time')\n",
    "mean_times = [mean_times[node].total_seconds() / (24 * 60 * 60) for node in G_ships_ports.nodes() if node.startswith(\"P\")]\n",
    "betweenness = nx.degree_centrality(G_ships_ports)\n",
    "\n",
    "\n",
    "x = [betweenness[node] for node in G_ships_ports.nodes() if node.startswith(\"P\")]\n",
    "y = mean_times\n",
    "plt.figure(dpi=200, figsize=(5,3))\n",
    "plt.scatter(x, y, s=2, c=\"k\")\n",
    "plt.xlabel('Betweenness Centrality')\n",
    "plt.ylabel('Mean Time in Port (days)')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Country Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "G_country = nx.Graph()\n",
    "\n",
    "# group the ports by country\n",
    "ports_by_country = defaultdict(list)\n",
    "for node_id, node_data in G_ships_ports.nodes(data=True):\n",
    "    country = node_data[\"country\"]\n",
    "    ports_by_country[country].append(node_id)\n",
    "\n",
    "# create a node for each country\n",
    "for country, ports in ports_by_country.items():\n",
    "    G_country.add_node(country, no_trips=0)\n",
    "\n",
    "# create edges between countries based on the connections between their ports\n",
    "for u, v, edge_data in G_ships_ports.edges(data=True):\n",
    "    u_data = G_ships_ports.nodes[u]\n",
    "    v_data = G_ships_ports.nodes[v]\n",
    "    u_country = u_data[\"country\"]\n",
    "    v_country = v_data[\"country\"]\n",
    "    if u_country != v_country:\n",
    "        if G_country.has_edge(u_country, v_country):\n",
    "            G_country[u_country][v_country][\"no_trips\"] += edge_data[\"no_trips\"]\n",
    "            G_country[u_country][v_country][\"mean_dist\"] += edge_data[\"mean_dist\"]\n",
    "            G_country[u_country][v_country][\"std_dist\"] += edge_data[\"std_dist\"]\n",
    "            G_country[u_country][v_country][\"mean_time\"] += edge_data[\"mean_time\"]\n",
    "            G_country[u_country][v_country][\"std_time\"] += edge_data[\"std_time\"]\n",
    "        else:\n",
    "            G_country.add_edge(u_country, v_country, **edge_data)\n",
    "            # update the no_trips attribute of the nodes\n",
    "            G_country.nodes[u_country][\"no_trips\"] += edge_data[\"no_trips\"]\n",
    "            G_country.nodes[v_country][\"no_trips\"] += edge_data[\"no_trips\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_sizes = {}\n",
    "for node, data in G_country.nodes(data=True):\n",
    "    node_sizes[node] = data[\"no_trips\"] * 20  #\n",
    "\n",
    "edge_widths = []\n",
    "for u, v, data in G_country.edges(data=True):\n",
    "    edge_widths.append(data[\"no_trips\"] * 0.05) \n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "pos = nx.fruchterman_reingold_layout(G_country, weight='no_trips', k=4.5, seed=34) # 2, 7, 16, 17, 26, 30, 32, 24\n",
    "nx.draw_networkx_edges(G_country, pos, width=edge_widths)\n",
    "node_colors = [data[\"no_trips\"] for node, data in G_country.nodes(data=True)]\n",
    "sm = plt.cm.ScalarMappable(cmap='cool', norm=plt.Normalize(vmin=min(node_colors), vmax=max(node_colors)))\n",
    "sm.set_array([])\n",
    "nx.draw_networkx_nodes(G_country, pos, node_size=list(node_sizes.values()), node_color=node_colors, cmap='cool', alpha=0.8)\n",
    "nx.draw_networkx_labels(G_country, pos, font_size=8, font_color=\"k\", font_family=\"sans-serif\")\n",
    "cbar = plt.colorbar(sm, shrink=0.5, pad=-0.01)\n",
    "cbar.ax.set_ylabel('Number of Visits', rotation=90, fontsize=15)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Degree Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = nx.degree_centrality(G_country)\n",
    "\n",
    "node_sizes = [degree[node]*4000 for node in G_country.nodes()]\n",
    "\n",
    "edge_widths = []\n",
    "for u, v, data in G_country.edges(data=True):\n",
    "    edge_widths.append(data[\"no_trips\"] * 0.05)  \n",
    "\n",
    "\n",
    "# plot the graph\n",
    "plt.figure(figsize=(12, 10))\n",
    "pos = nx.fruchterman_reingold_layout(G_country, weight='no_trips', k=4.5, seed=34) # 2, 7, 16, 17, 26, 30, 32, 24\n",
    "nx.draw_networkx_edges(G_country, pos, width=edge_widths)\n",
    "nodes = nx.draw_networkx_nodes(G_country, pos, node_size=node_sizes, node_color=list(degree.values()), cmap='cool', alpha=0.8)\n",
    "nx.draw_networkx_labels(G_country, pos, font_size=8, font_color=\"k\", font_family=\"sans-serif\")\n",
    "sm = plt.cm.ScalarMappable(cmap='cool', norm=plt.Normalize(vmin=min(degree.values()), vmax=max(degree.values())))\n",
    "sm._A = []  # this line is necessary to avoid warnings\n",
    "cbar = plt.colorbar(sm, shrink=0.5, pad=-0.01)\n",
    "cbar.ax.set_ylabel('Node Degree Centrality', rotation=90, fontsize=14)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Betweenness Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "degree = nx.betweenness_centrality(G_country)\n",
    "\n",
    "\n",
    "node_sizes = [degree[node]*20000 for node in G_country.nodes()]\n",
    "\n",
    "edge_widths = []\n",
    "for u, v, data in G_country.edges(data=True):\n",
    "    edge_widths.append(data[\"no_trips\"] * 0.05)  \n",
    "\n",
    "\n",
    "# plot the graph\n",
    "plt.figure(figsize=(12, 10))\n",
    "pos = nx.fruchterman_reingold_layout(G_country, weight='no_trips', k=4.5, seed=34) # 2, 7, 16\n",
    "nx.draw_networkx_edges(G_country, pos, width=edge_widths)\n",
    "nodes = nx.draw_networkx_nodes(G_country, pos, node_size=node_sizes, node_color=list(degree.values()), cmap='cool', alpha=0.8)\n",
    "nx.draw_networkx_labels(G_country, pos, font_size=8, font_color=\"k\", font_family=\"sans-serif\")\n",
    "sm = plt.cm.ScalarMappable(cmap='cool', norm=plt.Normalize(vmin=min(degree.values()), vmax=max(degree.values())))\n",
    "sm._A = []  # this line is necessary to avoid warnings\n",
    "cbar = plt.colorbar(sm, shrink=0.5, pad=-0.01)\n",
    "cbar.ax.set_ylabel('Node Betweenness Centrality', rotation=90, fontsize=14)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eigencentrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = nx.eigenvector_centrality(G_country)\n",
    "\n",
    "node_sizes = [degree[node]*10000 for node in G_country.nodes()]\n",
    "\n",
    "edge_widths = []\n",
    "for u, v, data in G_country.edges(data=True):\n",
    "    edge_widths.append(data[\"no_trips\"] * 0.05)  \n",
    "\n",
    "\n",
    "# plot the graph\n",
    "plt.figure(figsize=(12, 10))\n",
    "pos = nx.fruchterman_reingold_layout(G_country, weight='no_trips', k=4.5, seed=34)\n",
    "nx.draw_networkx_edges(G_country, pos, width=edge_widths)\n",
    "nodes = nx.draw_networkx_nodes(G_country, pos, node_size=node_sizes, node_color=list(degree.values()), cmap='cool', alpha=0.8)\n",
    "nx.draw_networkx_labels(G_country, pos, font_size=8, font_color=\"k\", font_family=\"sans-serif\")\n",
    "sm = plt.cm.ScalarMappable(cmap='cool', norm=plt.Normalize(vmin=min(degree.values()), vmax=max(degree.values())))\n",
    "sm._A = [] \n",
    "cbar = plt.colorbar(sm, shrink=0.5, pad=-0.01)\n",
    "cbar.ax.set_ylabel('Node Eigen Centrality', rotation=90, fontsize=14)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Closesness Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = nx.closeness_centrality(G_country)\n",
    "\n",
    "node_sizes = [degree[node]**4 * 10000 for node in G_country.nodes()]\n",
    "\n",
    "edge_widths = []\n",
    "for u, v, data in G_country.edges(data=True):\n",
    "    edge_widths.append(data[\"no_trips\"] * 0.05)  # scale the width based on number of trips\n",
    "\n",
    "\n",
    "# plot the graph\n",
    "plt.figure(figsize=(12, 10))\n",
    "pos = nx.fruchterman_reingold_layout(G_country, weight='no_trips', k=4.5, seed=34)\n",
    "nx.draw_networkx_edges(G_country, pos, width=edge_widths)\n",
    "nodes = nx.draw_networkx_nodes(G_country, pos, node_size=node_sizes, node_color=list(degree.values()), cmap='cool', alpha=0.8)\n",
    "nx.draw_networkx_labels(G_country, pos, font_size=8, font_color=\"k\", font_family=\"sans-serif\")\n",
    "sm = plt.cm.ScalarMappable(cmap='cool', norm=plt.Normalize(vmin=min(degree.values()), vmax=max(degree.values())))\n",
    "sm._A = []  \n",
    "cbar = plt.colorbar(sm, shrink=0.5, pad=-0.01)\n",
    "cbar.ax.set_ylabel('Node Closeness Centrality', rotation=90, fontsize=14)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_G_ships_multi = nx.to_pandas_edgelist(G_ships_multi)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi to Single Graph but with self loop nodes as edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_ships = nx.Graph()\n",
    "\n",
    "for u, v in G_ships_multi.edges():\n",
    "    edge_dict = G_ships_multi[u][v]\n",
    "    no_trips = len(edge_dict)\n",
    "    dists = [edge_dict[i]['dist'] for i in range(no_trips)]\n",
    "    time_diffs = [edge_dict[i]['time'].total_seconds() for i in range(no_trips)]\n",
    "\n",
    "    if len(dists) > 0:\n",
    "        mean_dist, std_dist = np.mean(dists), np.std(dists)\n",
    "    else:\n",
    "        mean_dist, std_dist = np.nan, np.nan\n",
    "\n",
    "    if len(time_diffs) > 0:\n",
    "        mean_time, std_time = datetime.timedelta(seconds=np.mean(time_diffs)), datetime.timedelta(seconds=np.std(time_diffs))\n",
    "    else:\n",
    "        mean_time, std_time = np.nan, np.nan\n",
    "\n",
    "    if not G_ships.has_edge(u, v):\n",
    "        G_ships.add_edge(u, v, no_trips=no_trips, mean_dist=mean_dist, std_dist=std_dist, mean_time=mean_time, std_time=std_time)\n",
    "    else:\n",
    "        G_ships[u][v]['no_trips'] = no_trips\n",
    "        G_ships[u][v]['mean_dist'] = mean_dist\n",
    "        G_ships[u][v]['std_dist'] = std_dist\n",
    "        G_ships[u][v]['mean_time'] = mean_time\n",
    "        G_ships[u][v]['std_time'] = std_time\n",
    "\n",
    "\n",
    "# Add self-loop edges as nodes to the graph with the same attributes as the edges\n",
    "for u, v, edge_attrs in G_ships.edges(data=True):\n",
    "    if u == v:  # Check if it's a self-loop edge\n",
    "        lat = all_nodes.loc[all_nodes['id'] == u, 'lat'].iloc[0]\n",
    "        lon = all_nodes.loc[all_nodes['id'] == u, 'lon'].iloc[0]\n",
    "        G_ships.add_node(u, no_trips=edge_attrs['no_trips'], mean_dist=edge_attrs['mean_dist'], std_dist=edge_attrs['std_dist'], mean_time=edge_attrs['mean_time'], std_time=edge_attrs['std_time'], lat=lat, lon=lon)\n",
    "\n",
    "\n",
    "df_G_ships = nx.to_pandas_edgelist(G_ships)\n",
    "df_port_nodes = df_G_ships[(df_G_ships['source'] == df_G_ships['target']) & (df_G_ships['source'].str.startswith(\"P\"))]\n",
    "df_port_nodes = df_port_nodes.drop(columns=[\"mean_dist\", \"std_dist\"])\n",
    "df_edges = df_G_ships[df_G_ships['source'] != df_G_ships['target']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of edges where no_trips is 1\n",
    "count_no_trips_1 = len(df_edges[df_edges['no_trips'] == 1])\n",
    "percent_no_trips_1 = (count_no_trips_1 / len(df_edges)) * 100\n",
    "\n",
    "# Print the percentage\n",
    "print(\"Percentage of edges where no_trips is 1:\", percent_no_trips_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of edges where no_trips is 1\n",
    "count_no_trips_2 = df_edges[df_edges['no_trips'] < 10]\n",
    "count_no_trips_2 = len(count_no_trips_2[count_no_trips_2['no_trips'] > 0])\n",
    "percent_no_trips_2 = (count_no_trips_2 / len(df_edges)) * 100\n",
    "\n",
    "# Print the percentage\n",
    "print(\"Percentage of edges where no_trips is :\", percent_no_trips_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of edges where no_trips is 1\n",
    "count_no_trips_2 = df_edges[df_edges['no_trips'] > 100]\n",
    "count_no_trips_2 = len(count_no_trips_2[count_no_trips_2['no_trips'] > 0])\n",
    "percent_no_trips_2 = (count_no_trips_2 / len(df_edges)) * 100\n",
    "\n",
    "# Print the percentage\n",
    "print(\"Percentage of edges where no_trips is :\", percent_no_trips_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No. Trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(G_ships.nodes(data=True))\n",
    "# Sort the edges in descending order based on the no_trips attribute\n",
    "sorted_edges = sorted(G_ships.edges(data=True), key=lambda x: x[2]['no_trips'], reverse=True)\n",
    "\n",
    "from matplotlib import colors\n",
    "\n",
    "def G_no_trips_plot(G, undir=True, threshold=1, region=\"Global\", plot_df=False):\n",
    "    G.remove_edges_from(nx.selfloop_edges(G))\n",
    "    weights = [d['no_trips'] for u, v, d in G.edges(data=True)]\n",
    "\n",
    "    min_weight, max_weight = min(weights), max(weights)\n",
    "\n",
    "    pos_undir = {node:(data['lon'], data['lat']) for node, data in G.nodes(data=True)}\n",
    "\n",
    "    single_edges = [(u, v) for u, v, d in G.edges(data=True) if d['no_trips'] <= 1]\n",
    "    repeated_edges = [(u, v) for u, v, d in G.edges(data=True) if d['no_trips'] > threshold]\n",
    "    repeated_edges = sorted(repeated_edges, key=lambda e: G.get_edge_data(e[0], e[1])['no_trips'])\n",
    "\n",
    "    plt, ax = crs_plot(world_bw=True, world_color=True, x_spac=20, y_spac=20)\n",
    "    if plot_df:\n",
    "        ax.scatter(df.lon, df.lat, c='k', edgecolor='None', marker = \"x\", alpha=0.7, s=0.2, linewidth=0.01)\n",
    "\n",
    "    norm = colors.PowerNorm(vmin=min_weight, vmax=max_weight, gamma=0.7)\n",
    "    cmap = plt.cm.get_cmap('gnuplot2', len(weights))\n",
    "    edge_colors = [cmap(norm(G.get_edge_data(u, v)['no_trips'])) for u, v in repeated_edges]\n",
    "\n",
    "    edge_weights = np.array([norm(G.get_edge_data(u, v)['no_trips']) for u, v in repeated_edges])\n",
    "\n",
    "    if region == \"CH\":\n",
    "        ax.set_extent([80, 160, -30, 50], crs=ccrs.PlateCarree())\n",
    "    elif region ==\"EU\":\n",
    "        ax.set_extent([-15, 40, 25, 72], crs=ccrs.PlateCarree())\n",
    "    elif region == \"US\":\n",
    "        ax.set_extent([-170, -45, 0, 70], crs=ccrs.PlateCarree())\n",
    "    elif region == \"ME\":\n",
    "        ax.set_extent([20, 100, -45, 40], crs=ccrs.PlateCarree())\n",
    "    elif region == \"AF\":\n",
    "        ax.set_extent([-20, 60, -45, 40], crs=ccrs.PlateCarree())\n",
    "    elif region == \"AUS\":\n",
    "        ax.set_extent([100, 155, -43, 8], crs=ccrs.PlateCarree())\n",
    "\n",
    "\n",
    "    nx.draw_networkx_nodes(G, pos_undir, node_color=\"k\", node_size=0.1)\n",
    "    if undir:\n",
    "        nx.draw_networkx_edges(G, pos_undir, edgelist=single_edges, width=0.1, alpha=0.3, edge_color=\"k\", style='dashed')\n",
    "        nx.draw_networkx_edges(G, pos_undir, edgelist=repeated_edges, width=edge_weights*8, edge_color=edge_colors, edge_cmap=cmap, style='solid', edge_vmin=min_weight, edge_vmax=max_weight)\n",
    "        # plt.title(\"Undirected Network\")\n",
    "\n",
    "    else:\n",
    "        nx.draw_networkx_edges(G, pos_undir, edgelist=single_edges, width=0.2, edge_color=\"gainsboro\", style='dashed', connectionstyle=\"arc3,rad=0.08\", arrowstyle='->', arrowsize=2, node_size=10) # single edges\n",
    "        nx.draw_networkx_edges(G, pos_undir, edgelist=repeated_edges, width=0.5, edge_color=edge_colors, edge_cmap=cmap, style='solid', edge_vmin=min_weight, edge_vmax=max_weight, connectionstyle=\"arc3,rad=0.08\", arrowstyle='->', arrowsize=2, node_size=10);\n",
    "        # plt.title(\"Directed Network\")\n",
    "\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    # cbar = plt.colorbar(sm, aspect=50, orientation=\"horizontal\", pad=0.1, shrink=1)\n",
    "    cbar = plt.colorbar(sm, aspect=50, orientation=\"horizontal\", pad=0.1, shrink=0.56)\n",
    "\n",
    "    cbar.ax.tick_params(labelsize=8)\n",
    "    cbar.ax.minorticks_on()\n",
    "    cbar.set_label('Number of Trips')\n",
    "\n",
    "# G_no_trips_plot(G_directed, undir=False, threshold=1, region=\"EU\")\n",
    "G_no_trips_plot(G_ships, undir=True, threshold=1, region=\"GL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cmasher as cmr\n",
    "\n",
    "def G_std_time_plot(G, undir=True, threshold=0, region=\"Global\"):\n",
    "    G.remove_edges_from(nx.selfloop_edges(G)) #NOTE\n",
    "\n",
    "    weights = [(d['std_time'].total_seconds() / (24 * 60 * 60)) / (d['mean_time'].total_seconds() / (24 * 60 * 60)) for u, v, d in G.edges(data=True) if d['mean_time'] is not None]\n",
    "    print(weights)\n",
    "    min_weight, max_weight = np.nanmin(weights), np.nanmax(weights)\n",
    "    print(min_weight, max_weight)\n",
    "    pos_undir = {node:(data['lon'], data['lat']) for node, data in G.nodes(data=True)}\n",
    "\n",
    "    # define edges\n",
    "    single_edges = [(u, v) for u, v, d in G.edges(data=True) if d['no_trips'] == 1] # edges with no_trips <= 1\n",
    "    repeated_edges = [(u, v) for u, v, d in G.edges(data=True) if d['mean_time'] is not None] # edges with no_trips > 1\n",
    "    repeated_edges = sorted(repeated_edges, key=lambda e: G.get_edge_data(e[0], e[1])['std_time'])\n",
    "\n",
    "    plt, ax = crs_plot(world_bw=True, world_color=True)\n",
    "    norm = colors.PowerNorm(vmin=min_weight, vmax=max_weight, gamma=0.4) # fit power curve to color values\n",
    "    # cmap = plt.cm.get_cmap('gnuplot2', len(weights))\n",
    "    cmap = cmr.get_sub_cmap('gnuplot2', 0, 0.95)\n",
    "\n",
    "\n",
    "    edge_weights = np.array([norm(G.get_edge_data(u, v)['std_dist']) for u, v in repeated_edges])\n",
    "\n",
    "    # edge_colors = [cmap(norm(G.get_edge_data(u, v)['std_time'].total_seconds() / (24 * 60 * 60) )) for u, v in repeated_edges]\n",
    "    edge_colors = [cmap(norm((G.get_edge_data(u, v)['std_time'].total_seconds() / (24 * 60 * 60) )/ (G.get_edge_data(u, v)['mean_time'].total_seconds() / (24 * 60 * 60)))) for u, v in repeated_edges]\n",
    "    \n",
    "    if region == \"CH\":\n",
    "        ax.set_extent([90, 150, -30, 50], crs=ccrs.PlateCarree())\n",
    "    elif region ==\"EU\":\n",
    "        ax.set_extent([-20, 50, 20, 75], crs=ccrs.PlateCarree())\n",
    "    elif region == \"US\":\n",
    "        ax.set_extent([-170, -45, 0, 70], crs=ccrs.PlateCarree())\n",
    "    elif region == \"ME\":\n",
    "        ax.set_extent([20, 100, -45, 40], crs=ccrs.PlateCarree())\n",
    "    elif region == \"AF\":\n",
    "        ax.set_extent([-20, 60, -45, 40], crs=ccrs.PlateCarree())\n",
    "\n",
    "\n",
    "    # nx.draw_networkx_nodes(G, pos_undir, node_color=\"k\", node_size=0.1)\n",
    "    if undir:\n",
    "        nx.draw_networkx_edges(G, pos_undir, edgelist=single_edges, width=0.2, edge_color=\"gainsboro\", style='dashed') # single edges\n",
    "        nx.draw_networkx_edges(G, pos_undir, edgelist=repeated_edges, width=edge_weights*0.08, edge_color=edge_colors, edge_cmap=cmap, style='solid', edge_vmin=min_weight, edge_vmax=max_weight) # repeated edges\n",
    "\n",
    "    else:\n",
    "        nx.draw_networkx_edges(G, pos_undir, edgelist=single_edges, width=0.2, edge_color=\"gainsboro\", style='dashed', connectionstyle=\"arc3,rad=0.08\", arrowstyle='->', arrowsize=2, node_size=10) # single edges\n",
    "        nx.draw_networkx_edges(G, pos_undir, edgelist=repeated_edges, width=0.5, edge_color=edge_colors, edge_cmap=cmap, style='solid', edge_vmin=min_weight, edge_vmax=max_weight, connectionstyle=\"arc3,rad=0.08\", arrowstyle='->', arrowsize=2, node_size=10);\n",
    "\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    cbar = plt.colorbar(sm, aspect=50, orientation=\"horizontal\", pad=0.1)\n",
    "    cbar.ax.tick_params(labelsize=8) \n",
    "    cbar.ax.minorticks_on()\n",
    "    cbar.set_label('Time Coefficient of Variation')\n",
    "\n",
    "G_std_time_plot(G_ships, undir=True, threshold=1, region=\"World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def G_std_time_plot(G, undir=True, threshold=0, region=\"Global\"):\n",
    "    G.remove_edges_from(nx.selfloop_edges(G)) #NOTE\n",
    "\n",
    "    # weights = [d['std_time'].total_seconds() / (24 * 60 * 60) for u, v, d in G.edges(data=True)]\n",
    "    weights = [(d['std_dist']) / (d['mean_dist']) for u, v, d in G.edges(data=True) if d['mean_time'] is not None]\n",
    "    print(weights)\n",
    "    min_weight, max_weight = np.nanmin(weights), np.nanmax(weights)\n",
    "    print(min_weight, max_weight)\n",
    "    # get longitude and latitude positions of nodes\n",
    "    pos_undir = {node:(data['lon'], data['lat']) for node, data in G.nodes(data=True)}\n",
    "\n",
    "    # define edges\n",
    "    single_edges = [(u, v) for u, v, d in G.edges(data=True) if pd.isnull(d['std_dist'])] # edges with no_trips <= 1\n",
    "\n",
    "    # repeated_edges = [(u, v) for u, v, d in G.edges(data=True) if d['std_time'].total_seconds() / (24 * 60 * 60) > threshold] # edges with no_trips > 1\n",
    "    repeated_edges = [(u, v) for u, v, d in G.edges(data=True) if (d['std_dist']) > threshold and d['mean_dist'] is not None] # edges with no_trips > 1\n",
    "    repeated_edges = sorted(repeated_edges, key=lambda e: G.get_edge_data(e[0], e[1])['std_dist'])\n",
    "\n",
    "    plt, ax = crs_plot(world_bw=True, world_color=True)\n",
    "    norm = colors.PowerNorm(vmin=min_weight, vmax=max_weight, gamma=0.6) # fit power curve to color values\n",
    "    cmap = plt.cm.get_cmap('gnuplot2', len(weights))\n",
    "\n",
    "    edge_colors = [cmap(norm(G.get_edge_data(u, v)['std_dist'])) for u, v in repeated_edges]\n",
    "\n",
    "    edge_weights = np.array([norm(G.get_edge_data(u, v)['std_dist']) for u, v in repeated_edges])\n",
    "    print(edge_weights)\n",
    "\n",
    "\n",
    "    # edge_colors = [cmap(norm(G.get_edge_data(u, v)['std_time'].total_seconds() / (24 * 60 * 60) )) for u, v in repeated_edges]\n",
    "    edge_colors = [cmap(norm((G.get_edge_data(u, v)['std_dist'])/ (G.get_edge_data(u, v)['mean_dist']))) for u, v in repeated_edges]\n",
    "    \n",
    "    if region == \"CH\":\n",
    "        ax.set_extent([90, 150, -30, 50], crs=ccrs.PlateCarree())\n",
    "    elif region ==\"EU\":\n",
    "        ax.set_extent([-20, 50, 20, 75], crs=ccrs.PlateCarree())\n",
    "    elif region == \"US\":\n",
    "        ax.set_extent([-170, -45, 0, 70], crs=ccrs.PlateCarree())\n",
    "    elif region == \"ME\":\n",
    "        ax.set_extent([20, 100, -45, 40], crs=ccrs.PlateCarree())\n",
    "    elif region == \"AF\":\n",
    "        ax.set_extent([-20, 60, -45, 40], crs=ccrs.PlateCarree())\n",
    "\n",
    "\n",
    "    # nx.draw_networkx_nodes(G, pos_undir, node_color=\"k\", node_size=0.1)\n",
    "    if undir:\n",
    "        nx.draw_networkx_edges(G, pos_undir, edgelist=single_edges, width=0.2, edge_color=\"gainsboro\", style='dashed') # single edges\n",
    "        nx.draw_networkx_edges(G, pos_undir, edgelist=repeated_edges, width=edge_weights*0.02, edge_color=edge_colors, edge_cmap=cmap, style='solid', edge_vmin=min_weight, edge_vmax=max_weight) # repeated edges\n",
    "\n",
    "    else:\n",
    "        nx.draw_networkx_edges(G, pos_undir, edgelist=single_edges, width=0.2, edge_color=\"gainsboro\", style='dashed', connectionstyle=\"arc3,rad=0.08\", arrowstyle='->', arrowsize=2, node_size=10) # single edges\n",
    "        nx.draw_networkx_edges(G, pos_undir, edgelist=repeated_edges, width=0.5, edge_color=edge_colors, edge_cmap=cmap, style='solid', edge_vmin=min_weight, edge_vmax=max_weight, connectionstyle=\"arc3,rad=0.08\", arrowstyle='->', arrowsize=2, node_size=10);\n",
    "\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    cbar = plt.colorbar(sm, aspect=50, orientation=\"horizontal\", pad=0.1)\n",
    "    cbar.ax.tick_params(labelsize=8) \n",
    "    cbar.ax.minorticks_on()\n",
    "    cbar.set_label('Time Standard Deviation (days)')\n",
    "    cbar.set_label('Distance Coefficient of Variation')\n",
    "\n",
    "# G_no_trips_plot(G_directed, undir=False, threshold=1, region=\"EU\")\n",
    "G_std_time_plot(G_ships, undir=True, threshold=1, region=\"World\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Voyages between Same Ports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib.cm import ScalarMappable\n",
    "%matplotlib inline\n",
    "node_comb = (224.0, 18.0)\n",
    "\n",
    "multi_edges = {}\n",
    "for u, v, attr in G_ships_multi.edges(data=True):\n",
    "    if attr.get('port_comb') == node_comb and u != v:\n",
    "        key = (u, v)\n",
    "        if key not in multi_edges:\n",
    "            multi_edges[key] = 0\n",
    "        multi_edges[key] += 1\n",
    "\n",
    "cmap = cm.get_cmap('gnuplot2_r')\n",
    "edge_counts = list(multi_edges.values())\n",
    "edge_norm = colors.Normalize(vmin=min(edge_counts), vmax=max(edge_counts))\n",
    "\n",
    "plt, ax = crs_plot(world_bw=True, world_color=True, x_spac=10, y_spac=10)\n",
    "edge_list = [(u, v) for (u, v) in G_ships_multi.edges() if u != v]\n",
    "\n",
    "nx.draw_networkx_nodes(G_ships_multi, pos_ships, alpha=0.5, node_color=\"k\", node_size=0.1).set_zorder(1)\n",
    "nx.draw_networkx_edges(G_ships_multi, pos_ships, width=0.1, alpha=0.1, edge_color=\"k\", edgelist=edge_list).set_zorder(1)\n",
    "\n",
    "sorted_edges = sorted(multi_edges.items(), key=lambda x: x[1], reverse=False)\n",
    "\n",
    "pos_ships = {node:(data['lon'], data['lat']) for node, data in G_ships_multi.nodes(data=True)}\n",
    "\n",
    "for edge, count in sorted_edges:\n",
    "    color = cmap(edge_norm(count))\n",
    "    nx.draw_networkx_edges(G_ships_multi, pos_ships, edgelist=[edge], width=2, edge_color=color).set_zorder(2)\n",
    "\n",
    "edges = [(u, v) for u, v, attr in G_ships_multi.edges(data=True) \n",
    "         if attr.get('port_comb') == node_comb and u != v]\n",
    "nodes_red = set(u for u, v in edges) | set(v for u, v in edges)\n",
    "nodes_blue = {node for node in nodes_red if G_ships_multi.nodes[node]['node_type'] == \"P\"}\n",
    "\n",
    "nx.draw_networkx_nodes(G_ships_multi, pos_ships, nodelist=nodes_red - nodes_blue, node_size=0.5, node_color='k').set_zorder(3)\n",
    "nx.draw_networkx_nodes(G_ships_multi, pos_ships, nodelist=[\"P\" + str(int(node_comb[0]))], node_size=20, node_color='limegreen', node_shape=\"d\", label='Start Port').set_zorder(4)\n",
    "nx.draw_networkx_nodes(G_ships_multi, pos_ships, nodelist=[\"P\" + str(int(node_comb[1]))], node_size=20, node_color='r', node_shape=\"d\", label='End Port').set_zorder(4)\n",
    "# plt.legend(frameon=False, loc=\"upper right\")\n",
    "sm = ScalarMappable(cmap=cmap, norm=edge_norm)\n",
    "sm.set_array([])\n",
    "# cbar = plt.colorbar(sm, orientation='vertical', shrink=1, aspect=40, pad=0.1)\n",
    "cbar = plt.colorbar(sm, orientation='horizontal', shrink=1, aspect=40, pad=0.06)\n",
    "\n",
    "# cbar = plt.colorbar(sm, orientation='horizontal', shrink=0.85, aspect=40, ticks=np.arange(1, 5+1, 1), pad=0.06)\n",
    "cbar.ax.tick_params(labelsize=8) \n",
    "cbar.set_label('No. Trips')\n",
    "\n",
    "total_imos = set()\n",
    "for u, v, attr in G_ships_multi.edges(data=True):\n",
    "    if attr.get('port_comb') == node_comb:\n",
    "        total_imos.add(attr.get('ship_imo'))\n",
    "\n",
    "print(f\"Total number of IMOs for port combination {node_comb}: {len(total_imos)}\")\n",
    "\n",
    "edge_coords = [(pos_ships[start], pos_ships[end]) for start, end in multi_edges.keys()]\n",
    "x_coords = [coord[0][0] for coord in edge_coords] + [coord[1][0] for coord in edge_coords]\n",
    "y_coords = [coord[0][1] for coord in edge_coords] + [coord[1][1] for coord in edge_coords]\n",
    "plt.xlim(min(x_coords)-1, max(x_coords)+1)\n",
    "plt.ylim(min(y_coords)-1, max(y_coords)+1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(224, 18)\n",
    "#(23, 224)\n",
    "#(34, 301)\n",
    "#(139, 18)\n",
    "df_filtered = df_G_ships_multi.loc[(df_G_ships_multi['port_comb'] == (139, 18))]\n",
    "rows = []\n",
    "for name, group in df_filtered.groupby('ship_imo'):\n",
    "    time_sum = group.time.sum()\n",
    "    dist_sum = group.dist.sum()\n",
    "    rows.append({'imo': name, 'data': group, 'time_sum': time_sum, 'dist_sum': dist_sum})\n",
    "df_grouped = pd.DataFrame(rows)\n",
    "print(df_grouped.time_sum.std().total_seconds()/(24*60*60))\n",
    "print(df_grouped.time_sum.std()/df_grouped.time_sum.mean())\n",
    "print(\"-------\")\n",
    "print(df_grouped.dist_sum.std())\n",
    "print(df_grouped.dist_sum.mean())\n",
    "\n",
    "print(df_grouped.dist_sum.std()/df_grouped.dist_sum.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pos_ships = {node:(data['lon'], data['lat']) for node, data in G_ships_multi.nodes(data=True)}\n",
    "\n",
    "\n",
    "plt, ax = crs_plot(world_bw=True, world_color=False)\n",
    "\n",
    "node_labels = {n: n if n in ['P12', 'P13'] else '' for n in G_ships_multi.nodes()}\n",
    "nx.draw_networkx_nodes(G_ships_multi, pos_ships, node_color=\"k\", node_size=0.5);\n",
    "# nx.draw_networkx_labels(G_ships_multi, pos_ships, labels=node_labels, font_size=4);\n",
    "nx.draw_networkx_labels(G_ships_multi, pos_ships, font_size=4);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "port_comb_list = []\n",
    "total_imos_list = []\n",
    "\n",
    "for node_comb in unique_port_combs:\n",
    "    if node_comb[0] != node_comb[1]:\n",
    "        # get total_imos for the current port_combination\n",
    "        total_imos = set()\n",
    "        for u, v, attr in G_ships_multi.edges(data=True):\n",
    "            if attr.get('port_comb') == node_comb:\n",
    "                total_imos.add(attr.get('ship_imo'))\n",
    "        # append to lists\n",
    "        port_comb_list.append(node_comb)\n",
    "        total_imos_list.append(len(total_imos))\n",
    "\n",
    "plt.scatter(port_comb_list, total_imos_list)\n",
    "plt.xlabel('Port Combination')\n",
    "plt.ylabel('Total IMOs')\n",
    "plt.title('Zipf\\'s Law Plot')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directed Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_ships_multi_dir = nx.MultiDiGraph()\n",
    "\n",
    "for imo, row in df_ship_network_T.iterrows():\n",
    "    row_data = row.T.iloc[0]\n",
    "\n",
    "    for _, sub_row in row_data.iterrows():\n",
    "        port_comb = sub_row[0]\n",
    "        for _, node_group in sub_row[-1].iterrows():\n",
    "            node_comb = node_group['betw_node']\n",
    "            G_ships_multi_dir.add_edge(node_comb[0], node_comb[1], \n",
    "                                       time=node_group.loc['time_diff'], \n",
    "                                       dist=node_group.loc['dist'], \n",
    "                                       start_month=node_group.loc['start_month'],\n",
    "                                       ship_imo=imo, \n",
    "                                       port_comb=port_comb)\n",
    "\n",
    "            \n",
    "for i, row in all_nodes.iterrows():\n",
    "    if row.id.startswith(\"N\"):\n",
    "        node_type = \"N\"\n",
    "    elif row.id.startswith(\"P\"):\n",
    "        node_type = \"P\"\n",
    "    G_ships_multi_dir.add_node(row.id, lat=row['lat'], lon=row['lon'], node_type=node_type)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "# Create an empty directed graph\n",
    "G_ships_dir = nx.DiGraph()\n",
    "\n",
    "for u, v, edge_dict in G_ships_multi_dir.edges(keys=True):\n",
    "    no_trips = len(G_ships_multi_dir.get_edge_data(u, v))\n",
    "    dists = [G_ships_multi_dir[u][v][key]['dist'] for key in G_ships_multi_dir[u][v]]\n",
    "    time_diffs = [G_ships_multi_dir[u][v][key]['time'].total_seconds() for key in G_ships_multi_dir[u][v]]\n",
    "\n",
    "    if len(dists) > 0:\n",
    "        mean_dist, std_dist = np.mean(dists), np.std(dists)\n",
    "    else:\n",
    "        mean_dist, std_dist = np.nan, np.nan\n",
    "\n",
    "    if len(time_diffs) > 0:\n",
    "        mean_time, std_time = datetime.timedelta(seconds=np.mean(time_diffs)), datetime.timedelta(seconds=np.std(time_diffs))\n",
    "    else:\n",
    "        mean_time, std_time = np.nan, np.nan\n",
    "\n",
    "    G_ships_dir.add_edge(u, v, no_trips=no_trips, mean_dist=mean_dist, std_dist=std_dist, mean_time=mean_time, std_time=std_time)\n",
    "\n",
    "# # Add nodes to the graph\n",
    "# for i, row in all_nodes.iterrows():\n",
    "#     if row.id.startswith(\"N\"):\n",
    "#         node_type = \"N\"\n",
    "#         G_ships_dir.add_node(row.id, lat=row['lat'], lon=row['lon'], node_type=node_type)\n",
    "\n",
    "# Add self-loop edges as nodes to the graph with the same attributes as the edges\n",
    "for u, v, edge_attrs in G_ships_dir.edges(data=True):\n",
    "    if u == v:  # Check if it's a self-loop edge\n",
    "        lat = all_nodes.loc[all_nodes['id'] == u, 'lat'].iloc[0]\n",
    "        lon = all_nodes.loc[all_nodes['id'] == u, 'lon'].iloc[0]\n",
    "\n",
    "        G_ships_dir.add_node(u, no_trips=edge_attrs['no_trips'], mean_dist=edge_attrs['mean_dist'], std_dist=edge_attrs['std_dist'], mean_time=edge_attrs['mean_time'], std_time=edge_attrs['std_time'], lat=lat, lon=lon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_ships_dir.remove_edges_from(nx.selfloop_edges(G_ships_dir))\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Sort the edges in descending order based on the no_trips attribute\n",
    "# sorted_edges = sorted(G.edges(data=True), key=lambda x: x[2]['no_trips'], reverse=True)\n",
    "\n",
    "# Print the sorted edges and attributes of the new graph\n",
    "# for u, v, data in sorted_edges:\n",
    "#     print(f\"({u}, {v}): {data['no_trips']}\")\n",
    "\n",
    "from matplotlib import colors\n",
    "\n",
    "def G_no_trips_plot_2(G, undir=True, threshold=1, region=\"Global\", plot_df=False):\n",
    "    G.remove_edges_from(nx.selfloop_edges(G))\n",
    "    weights = [d['no_trips'] for u, v, d in G.edges(data=True)]\n",
    "    min_weight, max_weight = min(weights), max(weights)\n",
    "\n",
    "    # get longitude and latitude positions of nodes\n",
    "\n",
    "    print(G.nodes(data=True))\n",
    "    pos_undir = {node:(data['lon'], data['lat']) for node, data in G.nodes(data=True)}\n",
    "\n",
    "    # define edges\n",
    "    single_edges = [(u, v) for u, v, d in G.edges(data=True) if d['no_trips'] <= 1] # edges with no_trips <= 1\n",
    "\n",
    "    repeated_edges = [(u, v) for u, v, d in G.edges(data=True) if d['no_trips'] > threshold] # edges with no_trips > 1\n",
    "    repeated_edges = sorted(repeated_edges, key=lambda e: G.get_edge_data(e[0], e[1])['no_trips'],  reverse=False)\n",
    "\n",
    "    plt, ax = crs_plot(world_bw=True, world_color=True, x_spac=2, y_spac=2)\n",
    "\n",
    "    if plot_df:\n",
    "        ax.scatter(df.lon, df.lat, c='k', edgecolor='None', marker = \"x\", alpha=0.7, s=0.2, linewidth=0.01)\n",
    "\n",
    "    norm = colors.PowerNorm(vmin=min_weight, vmax=max_weight, gamma=0.6) # fit power curve to color values\n",
    "    cmap = plt.cm.get_cmap('gnuplot2', len(weights))\n",
    "    edge_colors = [cmap(norm(G.get_edge_data(u, v)['no_trips'])) for u, v in repeated_edges]\n",
    "\n",
    "    edge_weights = np.array([norm(G.get_edge_data(u, v)['no_trips']) for u, v in repeated_edges])\n",
    "    if region == \"CH\":\n",
    "        ax.set_extent([80, 160, -30, 50], crs=ccrs.PlateCarree())\n",
    "    elif region ==\"EU\":\n",
    "        ax.set_extent([-20, 44, 20, 72], crs=ccrs.PlateCarree())\n",
    "    elif region == \"US\":\n",
    "        ax.set_extent([-170, -45, 0, 70], crs=ccrs.PlateCarree())\n",
    "    elif region == \"ME\":\n",
    "        ax.set_extent([20, 100, -45, 40], crs=ccrs.PlateCarree())\n",
    "    elif region == \"AF\":\n",
    "        ax.set_extent([-20, 60, -45, 40], crs=ccrs.PlateCarree())\n",
    "    elif region == \"AUS\":\n",
    "        ax.set_extent([100, 155, -43, 8], crs=ccrs.PlateCarree())\n",
    "    elif region == \"SING\":\n",
    "        ax.set_extent([100, 155, -22, 20], crs=ccrs.PlateCarree())\n",
    "    elif region == \"MECH\":\n",
    "        ax.set_extent([40, 140, -30, 20], crs=ccrs.PlateCarree())\n",
    "    elif region ==\"DK\":\n",
    "        ax.set_extent([8, 16, 53.5, 58], crs=ccrs.PlateCarree())\n",
    "\n",
    "    ports = [node for node in G.nodes() if node.startswith(\"P\")]    \n",
    "    nodes = [node for node in G.nodes() if node.startswith(\"N\")]\n",
    "\n",
    "    nx.draw_networkx_nodes(G, pos_undir, nodelist=nodes, node_color=\"k\", node_size=10)\n",
    "    nx.draw_networkx_nodes(G, pos_undir, nodelist=ports,  node_color=\"red\", node_shape=\"^\", node_size=15)\n",
    "\n",
    "    if undir:\n",
    "        nx.draw_networkx_edges(G, pos_undir, edgelist=single_edges, width=0.005, edge_color=\"k\", style='dashed') # single edges gainsboro\n",
    "        nx.draw_networkx_edges(G, pos_undir, edgelist=repeated_edges, width=edge_weights*0.2, edge_color=edge_colors, edge_cmap=cmap, style='solid', edge_vmin=min_weight, edge_vmax=max_weight) # repeated edges\n",
    "\n",
    "    else:\n",
    "        nx.draw_networkx_edges(G, pos_undir, edgelist=single_edges, width=0.05, edge_color=\"k\", style='dashed', connectionstyle=\"arc3,rad=0.1\", arrowstyle='->', arrowsize=5, node_size=2) # single edges\n",
    "        nx.draw_networkx_edges(G, pos_undir, edgelist=repeated_edges, width=edge_weights*5,edge_color=edge_colors, edge_cmap=cmap, style='solid', edge_vmin=min_weight, edge_vmax=max_weight, connectionstyle=\"arc3,rad=0.11\", arrowstyle='->', arrowsize=5, node_size=2);\n",
    "\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    cbar = plt.colorbar(sm, aspect=50, orientation=\"horizontal\", pad=0.1, shrink=1)\n",
    "    cbar.ax.tick_params(labelsize=8)\n",
    "    cbar.ax.minorticks_on()\n",
    "    cbar.set_label('Number of Trips')\n",
    "\n",
    "G_no_trips_plot_2(G_ships_dir, undir=False, threshold=1, region=\"DK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "# net number of trips between each pair of nodes\n",
    "net_trips = {}\n",
    "G_ships_dir.remove_edges_from(nx.selfloop_edges(G_ships_dir))\n",
    "for u, v, data in G_ships_dir.edges(data=True):\n",
    "    u_v_trips = data.get('no_trips', 0)\n",
    "    v_u_trips = G_ships_dir[v].get(u, {}).get('no_trips', 0)\n",
    "    net_trips[(u, v)] = abs(u_v_trips - v_u_trips)  # compute absolute difference\n",
    "\n",
    "# Plot the graph with edges colored by net number of trips\n",
    "plt, ax = crs_plot(world_bw=True, x_spac=45, y_spac=45)\n",
    "pos = {node: (G_ships_dir.nodes[node]['lon'], G_ships_dir.nodes[node]['lat']) for node in G_ships_dir.nodes()}\n",
    "\n",
    "\n",
    "repeated_edges = [(u, v) for u, v, d in G_ships_dir.edges(data=True) if d['no_trips'] > 20] # edges with no_trips > 1\n",
    "repeated_edges = sorted(repeated_edges, key=lambda e: G_ships_dir.get_edge_data(e[0], e[1])['no_trips'])\n",
    "\n",
    "edge_weights = np.array([norm(G_ships_dir.get_edge_data(u, v)['no_trips']) for u, v in repeated_edges])\n",
    "\n",
    "mappable = cm.ScalarMappable(norm=plt.Normalize(vmin=edge_weights.min(), vmax=edge_weights.max()), cmap=plt.cm.magma)\n",
    "\n",
    "# Draw edges with arrows in one direction only\n",
    "visited_edges = set()\n",
    "for u, v, data in G_ships_dir.edges(data=True):\n",
    "    if (u, v) in visited_edges or (v, u) in visited_edges:\n",
    "        continue\n",
    "    visited_edges.add((u, v))\n",
    "    visited_edges.add((v, u))\n",
    "\n",
    "    if G_ships_dir[v].get(u, {}).get('no_trips', 0) > data.get('no_trips', 0):\n",
    "        arrowstyle = '<-'\n",
    "    else:\n",
    "        arrowstyle = '->'\n",
    "    edge_color = mappable.to_rgba(data['no_trips'])\n",
    "    edge_width = abs(net_trips[(u, v)]) / 25\n",
    "    nx.draw_networkx_edges(G_ships_dir, pos, edgelist=[(u, v)], width=edge_width, edge_color=edge_color, arrowstyle=arrowstyle, connectionstyle=\"arc3,rad=0.08\", arrowsize=5, node_size=1)\n",
    "\n",
    "region = \"GLOBAL\"\n",
    "# Set the extent of the plot based on the region\n",
    "if region == \"CH\":\n",
    "    ax.set_extent([90, 150, -30, 50], crs=ccrs.PlateCarree())\n",
    "elif region ==\"EU\":\n",
    "    ax.set_extent([-20, 50, 20, 75], crs=ccrs.PlateCarree())\n",
    "elif region == \"US\":\n",
    "    ax.set_extent([-170, -45, 0, 70], crs=ccrs.PlateCarree())\n",
    "elif region == \"ME\":\n",
    "    ax.set_extent([20, 110, -20, 40], crs=ccrs.PlateCarree())\n",
    "elif region == \"MEL\":\n",
    "    ax.set_extent([20, 110, -50, 20], crs=ccrs.PlateCarree())\n",
    "elif region == \"AF\":\n",
    "    ax.set_extent([-20, 60, -45, 40], crs=ccrs.PlateCarree())\n",
    "elif region ==\"DK\":\n",
    "    ax.set_extent([-5, 30, 46, 64], crs=ccrs.PlateCarree())\n",
    "\n",
    "cbar = plt.colorbar(mappable, aspect=50, orientation=\"horizontal\", pad=0.1)\n",
    "cbar.ax.tick_params(labelsize=8) \n",
    "cbar.ax.minorticks_on()\n",
    "cbar.set_label('Net No. Trips')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "net_trips = {}\n",
    "G_ships_dir.remove_edges_from(nx.selfloop_edges(G_ships_dir))\n",
    "\n",
    "for u, v, data in G_ships_dir.edges(data=True):\n",
    "    u_v_trips = data.get('no_trips', 0)\n",
    "    v_u_trips = G_ships_dir[v].get(u, {}).get('no_trips', 0)\n",
    "    net_trips[(u, v)] = abs(u_v_trips - v_u_trips) \n",
    "\n",
    "# sort edges by net_trips value in descending order\n",
    "edges_sorted = sorted(G_ships_dir.edges(data=True), key=lambda x: net_trips[(x[0], x[1])], reverse=False)\n",
    "\n",
    "visited_edges = set()\n",
    "plt, ax = crs_plot(world_bw=True, world_color=True, x_spac=45, y_spac=45)\n",
    "\n",
    "edge_weights = [data['no_trips'] for u, v, data in G_ships_dir.edges(data=True)]\n",
    "norm = colors.PowerNorm(gamma=0.4, vmin=min(edge_weights), vmax=max(edge_weights))\n",
    "mappable = cm.ScalarMappable(norm=norm, cmap=plt.cm.gnuplot2)\n",
    "\n",
    "# loop over sorted edges and draw them in order\n",
    "for u, v, data in edges_sorted:\n",
    "    if (u, v) in visited_edges or (v, u) in visited_edges:\n",
    "        continue\n",
    "    visited_edges.add((u, v))\n",
    "    visited_edges.add((v, u))\n",
    "\n",
    "    if net_trips[(u, v)] > 2: \n",
    "        if G_ships_dir[v].get(u, {}).get('no_trips', 0) > data.get('no_trips', 0):\n",
    "            arrowstyle = '<-'\n",
    "        else:\n",
    "            arrowstyle = '->'\n",
    "\n",
    "        if net_trips[(u, v)] > 10:\n",
    "            edge_width = 2.5\n",
    "        else:\n",
    "            edge_width = norm(net_trips[(u, v)])*5\n",
    "        edge_color = mappable.to_rgba(data['no_trips'])  # apply the norm to the edge color\n",
    "\n",
    "        nx.draw_networkx_edges(G_ships_dir, pos, edgelist=[(u, v)], width=edge_width, edge_color=edge_color, arrowstyle=arrowstyle, connectionstyle=\"arc3,rad=0.08\", arrowsize=4, node_size=1)\n",
    "\n",
    "region = \"CUST\"\n",
    "\n",
    "if region == \"CH\":\n",
    "    ax.set_extent([90, 150, -30, 50], crs=ccrs.PlateCarree())\n",
    "elif region ==\"EU\":\n",
    "    ax.set_extent([-20, 50, 20, 75], crs=ccrs.PlateCarree())\n",
    "elif region == \"US\":\n",
    "    ax.set_extent([-170, -45, 0, 70], crs=ccrs.PlateCarree())\n",
    "elif region == \"ME\":\n",
    "    ax.set_extent([20, 110, -20, 40], crs=ccrs.PlateCarree())\n",
    "elif region == \"MEL\":\n",
    "    ax.set_extent([20, 110, -50, 20], crs=ccrs.PlateCarree())\n",
    "elif region == \"AF\":\n",
    "    ax.set_extent([-20, 60, -45, 40], crs=ccrs.PlateCarree())\n",
    "elif region ==\"DK\":\n",
    "    ax.set_extent([-5, 30, 46, 64], crs=ccrs.PlateCarree())\n",
    "elif region ==\"CUST\":\n",
    "    ax.set_extent([-100, 180, -55, 80], crs=ccrs.PlateCarree())\n",
    "    \n",
    "cbar = plt.colorbar(mappable, aspect=50, orientation=\"horizontal\", pad=0.1)\n",
    "cbar.ax.tick_params(labelsize=8) \n",
    "cbar.ax.minorticks_on()\n",
    "cbar.set_label('Net No. Trips')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_trips = {}\n",
    "G_ships_dir.remove_edges_from(nx.selfloop_edges(G_ships_dir))\n",
    "\n",
    "# compute net_trips dictionary\n",
    "for u, v, data in G_ships_dir.edges(data=True):\n",
    "    u_v_trips = data.get('no_trips', 0)\n",
    "    v_u_trips = G_ships_dir[v].get(u, {}).get('no_trips', 0)\n",
    "    net_trips[(u, v)] = abs(u_v_trips - v_u_trips)  # compute absolute difference\n",
    "\n",
    "# sort edges by net_trips value in descending order\n",
    "edges_sorted = sorted(G_ships_dir.edges(data=True), key=lambda x: net_trips[(x[0], x[1])], reverse=False)\n",
    "\n",
    "visited_edges = set()\n",
    "plt, ax = crs_plot(world_bw=True, world_color=True, x_spac=10, y_spac=10)\n",
    "\n",
    "edge_weights = [data['no_trips'] for u, v, data in G_ships_dir.edges(data=True)]\n",
    "norm = colors.PowerNorm(gamma=0.4, vmin=min(edge_weights), vmax=max(edge_weights))\n",
    "mappable = cm.ScalarMappable(norm=norm, cmap=plt.cm.gnuplot2)\n",
    "\n",
    "# loop over sorted edges and draw them in order\n",
    "for u, v, data in edges_sorted:\n",
    "    if (u, v) in visited_edges or (v, u) in visited_edges:\n",
    "        continue\n",
    "    visited_edges.add((u, v))\n",
    "    visited_edges.add((v, u))\n",
    "\n",
    "    if net_trips[(u, v)] > 2: \n",
    "        if G_ships_dir[v].get(u, {}).get('no_trips', 0) > data.get('no_trips', 0):\n",
    "            arrowstyle = '<-'\n",
    "        else:\n",
    "            arrowstyle = '->'\n",
    "\n",
    "        if net_trips[(u, v)] > 10:\n",
    "            edge_width = 3\n",
    "        else:\n",
    "            edge_width = norm(net_trips[(u, v)])*8\n",
    "        edge_color = mappable.to_rgba(data['no_trips'])  # apply the norm to the edge color\n",
    "\n",
    "        nx.draw_networkx_edges(G_ships_dir, pos, edgelist=[(u, v)], width=edge_width, edge_color=edge_color, arrowstyle=arrowstyle, connectionstyle=\"arc3,rad=0.08\", arrowsize=5, node_size=1)\n",
    "\n",
    "region = \"CUST\"\n",
    "if region == \"CH\":\n",
    "    ax.set_extent([90, 150, -30, 50], crs=ccrs.PlateCarree())\n",
    "elif region ==\"EU\":\n",
    "    ax.set_extent([-20, 50, 20, 75], crs=ccrs.PlateCarree())\n",
    "elif region == \"US\":\n",
    "    ax.set_extent([-170, -45, 0, 70], crs=ccrs.PlateCarree())\n",
    "elif region == \"ME\":\n",
    "    ax.set_extent([20, 110, -20, 40], crs=ccrs.PlateCarree())\n",
    "elif region == \"MEL\":\n",
    "    ax.set_extent([20, 110, -50, 20], crs=ccrs.PlateCarree())\n",
    "elif region == \"AF\":\n",
    "    ax.set_extent([-20, 60, -45, 40], crs=ccrs.PlateCarree())\n",
    "elif region ==\"DK\":\n",
    "    ax.set_extent([-5, 30, 46, 64], crs=ccrs.PlateCarree())\n",
    "elif region ==\"CUST\":\n",
    "    ax.set_extent([-12, 33, 30, 62], crs=ccrs.PlateCarree())\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonal Variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "import pycountry_convert as pc\n",
    "\n",
    "def country_to_continent(country_name):\n",
    "    country_alpha2 = pc.country_name_to_country_alpha2(country_name)\n",
    "    country_continent_code = pc.country_alpha2_to_continent_code(country_alpha2)\n",
    "    country_continent_name = pc.convert_continent_code_to_continent_name(country_continent_code)\n",
    "    return country_continent_name\n",
    "\n",
    "\n",
    "def create_G_seasons(months_Qs):\n",
    "    G_seasonal_multi = nx.MultiDiGraph()\n",
    "    for u, v, edge_dict in G_ships_multi.edges(data=True):\n",
    "        if 'start_month' in edge_dict and edge_dict['start_month'] in months_Qs:\n",
    "            G_seasonal_multi.add_edge(u, v, **edge_dict)\n",
    "\n",
    "    G_seasonal = nx.Graph()\n",
    "\n",
    "    for u, v in G_seasonal_multi.edges():\n",
    "        edge_dict = G_seasonal_multi[u][v]\n",
    "        no_trips = len(edge_dict)\n",
    "        dists = [edge_dict[i]['dist'] for i in range(no_trips)]\n",
    "        time_diffs = [edge_dict[i]['time'].total_seconds() for i in range(no_trips)]\n",
    "\n",
    "        if len(dists) > 0:\n",
    "            mean_dist, std_dist = np.mean(dists), np.std(dists)\n",
    "        else:\n",
    "            mean_dist, std_dist = np.nan, np.nan\n",
    "\n",
    "        if len(time_diffs) > 0:\n",
    "            mean_time, std_time = datetime.timedelta(seconds=np.mean(time_diffs)), datetime.timedelta(seconds=np.std(time_diffs))\n",
    "        else:\n",
    "            mean_time, std_time = np.nan, np.nan\n",
    "\n",
    "        if not G_seasonal.has_edge(u, v):\n",
    "            G_seasonal.add_edge(u, v, no_trips=no_trips, mean_dist=mean_dist, std_dist=std_dist, mean_time=mean_time, std_time=std_time)\n",
    "        else:\n",
    "            G_seasonal[u][v]['no_trips'] = no_trips\n",
    "            G_seasonal[u][v]['mean_dist'] = mean_dist\n",
    "            G_seasonal[u][v]['std_dist'] = std_dist\n",
    "            G_seasonal[u][v]['mean_time'] = mean_time\n",
    "            G_seasonal[u][v]['std_time'] = std_time\n",
    "\n",
    "\n",
    "    # Add self-loop edges as nodes to the graph with the same attributes as the edges\n",
    "    for u, v, edge_attrs in G_seasonal.edges(data=True):\n",
    "        if u == v:  # Check if it's a self-loop edge\n",
    "            lat = all_nodes.loc[all_nodes['id'] == u, 'lat'].iloc[0]\n",
    "            lon = all_nodes.loc[all_nodes['id'] == u, 'lon'].iloc[0]\n",
    "            country = all_nodes.loc[all_nodes['id'] == u, 'country'].iloc[0]\n",
    "            # continent = country_to_continent(country)\n",
    "            G_seasonal.add_node(u, no_trips=edge_attrs['no_trips'], mean_dist=edge_attrs['mean_dist'], std_dist=edge_attrs['std_dist'], mean_time=edge_attrs['mean_time'], std_time=edge_attrs['std_time'], lat=lat, lon=lon, country=country)\n",
    "\n",
    "    return G_seasonal\n",
    "\n",
    "months_Q1 = [1,2,3]\n",
    "months_Q2 = [4,5,6]\n",
    "months_Q3 = [7,8,9]\n",
    "months_Q4 = [10,11,12]\n",
    "\n",
    "G_Q1 = create_G_seasons(months_Q1)\n",
    "G_Q2 = create_G_seasons(months_Q2)\n",
    "G_Q3 = create_G_seasons(months_Q3)\n",
    "G_Q4 = create_G_seasons(months_Q4)\n",
    "\n",
    "df_G_Q1 = nx.to_pandas_edgelist(G_Q1)\n",
    "df_G_Q2 = nx.to_pandas_edgelist(G_Q2)\n",
    "df_G_Q3 = nx.to_pandas_edgelist(G_Q3)\n",
    "df_G_Q4 = nx.to_pandas_edgelist(G_Q4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors\n",
    "\n",
    "def G_no_trips_plot(G, undir=True, threshold=1, region=\"Global\", plot_df=False):\n",
    "    sorted_edges = sorted(G.edges(data=True), key=lambda x: x[2]['no_trips'], reverse=True)\n",
    "\n",
    "\n",
    "    # nodes with no data\n",
    "    empty_nodes = [node for node, data in G.nodes(data=True) if not data]\n",
    "    G.remove_nodes_from(empty_nodes)\n",
    "\n",
    "\n",
    "    G.remove_edges_from(nx.selfloop_edges(G)) \n",
    "    weights = [d['no_trips'] for u, v, d in G.edges(data=True)]\n",
    "    min_weight, max_weight = min(weights), max(weights)\n",
    "\n",
    "    # get longitude and latitude positions of nodes\n",
    "\n",
    "    print(G.nodes(data=True))\n",
    "    pos_undir = {node:(data['lon'], data['lat']) for node, data in G.nodes(data=True)}\n",
    "\n",
    "    # define edges\n",
    "    single_edges = [(u, v) for u, v, d in G.edges(data=True) if d['no_trips'] <= 1] # edges with no_trips <= 1\n",
    "\n",
    "    repeated_edges = [(u, v) for u, v, d in G.edges(data=True) if d['no_trips'] > threshold] # edges with no_trips > 1\n",
    "    repeated_edges = sorted(repeated_edges, key=lambda e: G.get_edge_data(e[0], e[1])['no_trips'])\n",
    "\n",
    "    plt, ax = crs_plot(world_bw=True, world_color=False)\n",
    "\n",
    "    if plot_df:\n",
    "        ax.scatter(df.lon, df.lat, c='k', edgecolor='None', marker = \"x\", alpha=0.7, s=0.2, linewidth=0.01)\n",
    "\n",
    "    norm = colors.PowerNorm(vmin=min_weight, vmax=max_weight, gamma=0.5) # fit power curve to color values\n",
    "    cmap = plt.cm.get_cmap('magma_r', len(weights))\n",
    "    edge_colors = [cmap(norm(G.get_edge_data(u, v)['no_trips'])) for u, v in repeated_edges]\n",
    "\n",
    "    if region == \"CH\":\n",
    "        ax.set_extent([80, 160, -30, 50], crs=ccrs.PlateCarree())\n",
    "    elif region ==\"EU\":\n",
    "        ax.set_extent([-20, 44, 20, 72], crs=ccrs.PlateCarree())\n",
    "    elif region == \"US\":\n",
    "        ax.set_extent([-170, -45, 0, 70], crs=ccrs.PlateCarree())\n",
    "    elif region == \"ME\":\n",
    "        ax.set_extent([20, 100, -45, 40], crs=ccrs.PlateCarree())\n",
    "    elif region == \"AF\":\n",
    "        ax.set_extent([-20, 60, -45, 40], crs=ccrs.PlateCarree())\n",
    "    elif region == \"AUS\":\n",
    "        ax.set_extent([100, 155, -43, 8], crs=ccrs.PlateCarree())\n",
    "\n",
    "\n",
    "    nx.draw_networkx_nodes(G, pos_undir, node_color=\"k\", node_size=0.1)\n",
    "    if undir:\n",
    "        nx.draw_networkx_edges(G, pos_undir, edgelist=single_edges, width=0.2, edge_color=\"gainsboro\", style='dashed') # single edges gainsboro\n",
    "        nx.draw_networkx_edges(G, pos_undir, edgelist=repeated_edges, width=0.5, edge_color=edge_colors, edge_cmap=cmap, style='solid', edge_vmin=min_weight, edge_vmax=max_weight) # repeated edges\n",
    "\n",
    "    else:\n",
    "        nx.draw_networkx_edges(G, pos_undir, edgelist=single_edges, width=0.2, edge_color=\"gainsboro\", style='dashed', connectionstyle=\"arc3,rad=0.08\", arrowstyle='->', arrowsize=2, node_size=10) # single edges\n",
    "        nx.draw_networkx_edges(G, pos_undir, edgelist=repeated_edges, width=0.5, edge_color=edge_colors, edge_cmap=cmap, style='solid', edge_vmin=min_weight, edge_vmax=max_weight, connectionstyle=\"arc3,rad=0.08\", arrowstyle='->', arrowsize=2, node_size=10);\n",
    "\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    # cbar = plt.colorbar(sm, aspect=50, orientation=\"horizontal\", pad=0.1)\n",
    "    cbar = plt.colorbar(sm, aspect=50, orientation=\"horizontal\", pad=0.1, shrink=0.5)\n",
    "    cbar.ax.tick_params(labelsize=8)\n",
    "    cbar.ax.minorticks_on()\n",
    "    cbar.set_label('Number of Trips')\n",
    "\n",
    "G_no_trips_plot(G_Q1, undir=True, threshold=1, region=\"global\")\n",
    "G_no_trips_plot(G_Q2, undir=True, threshold=1, region=\"global\")\n",
    "G_no_trips_plot(G_Q3, undir=True, threshold=1, region=\"global\")\n",
    "G_no_trips_plot(G_Q4, undir=True, threshold=1, region=\"global\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "self_loops_Q1 = {edge for edge in G_Q1.edges() if edge[0] == edge[1] and edge[0].startswith('P')}\n",
    "self_loops_Q2 = {edge for edge in G_Q2.edges() if edge[0] == edge[1] and edge[0].startswith('P')}\n",
    "self_loops_Q3 = {edge for edge in G_Q3.edges() if edge[0] == edge[1] and edge[0].startswith('P')}\n",
    "self_loops_Q4 = {edge for edge in G_Q4.edges() if edge[0] == edge[1] and edge[0].startswith('P')}\n",
    "self_loops_all = self_loops_Q1 & self_loops_Q2 & self_loops_Q3 & self_loops_Q4\n",
    "\n",
    "mean_times_all_Q = [[G_Q1[edge[0]][edge[1]]['mean_time'].total_seconds() / (60*60*24) if edge in self_loops_Q1 else 0,\n",
    "                     G_Q2[edge[0]][edge[1]]['mean_time'].total_seconds() / (60*60*24) if edge in self_loops_Q2 else 0,\n",
    "                     G_Q3[edge[0]][edge[1]]['mean_time'].total_seconds() / (60*60*24) if edge in self_loops_Q3 else 0,\n",
    "                     G_Q4[edge[0]][edge[1]]['mean_time'].total_seconds() / (60*60*24) if edge in self_loops_Q4 else 0,\n",
    "                     edge[0]] for edge in self_loops_all]\n",
    "\n",
    "\n",
    "mean_times_all_Q = pd.DataFrame(mean_times_all_Q)\n",
    "mean_times_all_Q[\"COV\"] = mean_times_all_Q.std(axis=1)/(mean_times_all_Q.mean(axis=1))\n",
    "mean_times_all_Q['country'] = mean_times_all_Q.apply(lambda row: all_nodes.loc[all_nodes[\"id\"] == row[4], 'country'].iloc[0], axis=1)\n",
    "\n",
    "mean_times_china_Q = mean_times_all_Q.loc[mean_times_all_Q['country'] == 'China']\n",
    "\n",
    "common_self_loops_P_china = mean_times_china_Q[4].tolist()\n",
    "\n",
    "mean_times_Q1_china = mean_times_china_Q[0].tolist()\n",
    "mean_times_Q2_china = mean_times_china_Q[1].tolist()\n",
    "mean_times_Q3_china = mean_times_china_Q[2].tolist()\n",
    "mean_times_Q4_china = mean_times_china_Q[3].tolist()\n",
    "\n",
    "x = range(len(common_self_loops_P_china))\n",
    "colors = ['#FF5C74', '#E3ABAB', '#255C99', '#7EA3CC']\n",
    "labels = ['Q1', 'Q2', 'Q3', 'Q4']\n",
    "\n",
    "legend_patches = [mpatches.Patch(color=colors[i], label=labels[i]) for i in range(len(labels))]\n",
    "\n",
    "width = 0.2\n",
    "plt.figure(figsize=(9,3))\n",
    "plt.bar([i-width*3/2 for i in x], mean_times_Q1_china, width=width, color=colors[0], label='Q1')\n",
    "plt.bar([i-width/2 for i in x], mean_times_Q2_china, width=width, color=colors[1], label='Q2')\n",
    "plt.bar([i+width/2 for i in x], mean_times_Q3_china, width=width, color=colors[2], label='Q3')\n",
    "plt.bar([i+width*3/2 for i in x], mean_times_Q4_china, width=width, color=colors[3], label='Q4')\n",
    "plt.xticks(x, common_self_loops_P_china, rotation=90)\n",
    "plt.ylabel('Mean time (days)')\n",
    "plt.xlabel('Ports in China')\n",
    "plt.legend(handles=legend_patches)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NODE CENTRALITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import cmasher as cmr\n",
    "\n",
    "G_ships.remove_edges_from(nx.selfloop_edges(G_ships))\n",
    "\n",
    "# create a new edge attribute containing the converted values\n",
    "for u, v, data in G_ships.edges(data=True):\n",
    "    data['mean_time_seconds'] = data['mean_time'].total_seconds()\n",
    "\n",
    "# degree = nx.betweenness_centrality(G_ships, weight='mean_dist')\n",
    "# degree = nx.eigenvector_centrality(G_ships, weight='no_trips', max_iter=300)\n",
    "degree = nx.betweenness_centrality(G_ships, weight='mean_time_seconds')\n",
    "\n",
    "\n",
    "node_sizes = [degree[node]*50 for node in G_ships.nodes()]\n",
    "print(node_sizes)\n",
    "\n",
    "edge_widths = []\n",
    "for u, v, data in G_ships.edges(data=True):\n",
    "    edge_widths.append(data[\"no_trips\"] * 0.01)  # scale the width based on number of trips\n",
    "\n",
    "\n",
    "cmap = cmr.get_sub_cmap('gnuplot2', 0, 0.95)\n",
    "print(G_ships.nodes(data=True))\n",
    "\n",
    "plt, ax = crs_plot(world_bw=True, world_color=True)\n",
    "pos = {node:(data['lon'], data['lat']) for node, data in G_ships.nodes(data=True)}\n",
    "nx.draw_networkx_edges(G_ships, pos, width=edge_widths)\n",
    "nodes = nx.draw_networkx_nodes(G_ships, pos, node_size=node_sizes, node_color=list(degree.values()), cmap=cmap, alpha=0.8)\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=min(degree.values()), vmax=max(degree.values())))\n",
    "sm._A = []  \n",
    "cbar = plt.colorbar(sm, aspect=50, orientation=\"horizontal\", pad=0.1, shrink=1)\n",
    "cbar.ax.tick_params(labelsize=8)\n",
    "cbar.ax.minorticks_on()\n",
    "cbar.set_label('Node Betweenness Centality')\n",
    "\n",
    "region=\"GL\"\n",
    "\n",
    "if region == \"CH\":\n",
    "    ax.set_extent([80, 160, -30, 50], crs=ccrs.PlateCarree())\n",
    "elif region ==\"EU\":\n",
    "    ax.set_extent([-20, 44, 20, 72], crs=ccrs.PlateCarree())\n",
    "elif region == \"US\":\n",
    "    ax.set_extent([-170, -45, 0, 70], crs=ccrs.PlateCarree())\n",
    "elif region == \"ME\":\n",
    "    ax.set_extent([20, 100, -45, 40], crs=ccrs.PlateCarree())\n",
    "elif region == \"AF\":\n",
    "    ax.set_extent([-20, 60, -45, 40], crs=ccrs.PlateCarree())\n",
    "elif region == \"AUS\":\n",
    "    ax.set_extent([100, 155, -43, 8], crs=ccrs.PlateCarree())\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ais",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
